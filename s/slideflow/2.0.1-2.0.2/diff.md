# Comparing `tmp/slideflow-2.0.1-py3-none-any.whl.zip` & `tmp/slideflow-2.0.2-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,12 +1,12 @@
-Zip file size: 1837018 bytes, number of entries: 359
+Zip file size: 1838157 bytes, number of entries: 359
 -rw-rw-r--  2.0 unx     1411 b- defN 23-Apr-09 06:29 slideflow/__init__.py
 -rw-rw-r--  2.0 unx     1662 b- defN 23-Apr-09 06:29 slideflow/_backend.py
--rw-rw-r--  2.0 unx      497 b- defN 23-Apr-12 04:31 slideflow/_version.py
--rw-rw-r--  2.0 unx   159660 b- defN 23-Apr-10 16:45 slideflow/dataset.py
+-rw-rw-r--  2.0 unx      497 b- defN 23-Apr-17 18:28 slideflow/_version.py
+-rw-rw-r--  2.0 unx   159745 b- defN 23-Apr-14 13:28 slideflow/dataset.py
 -rw-rw-r--  2.0 unx     3733 b- defN 23-Apr-09 06:29 slideflow/errors.py
 -rw-rw-r--  2.0 unx    38304 b- defN 23-Apr-09 06:29 slideflow/heatmap.py
 -rw-rw-r--  2.0 unx    25615 b- defN 23-Apr-09 06:29 slideflow/mosaic.py
 -rw-rw-r--  2.0 unx   168044 b- defN 23-Apr-09 06:29 slideflow/project.py
 -rw-rw-r--  2.0 unx    33320 b- defN 23-Apr-09 06:29 slideflow/project_utils.py
 -rw-rw-r--  2.0 unx      978 b- defN 22-Jul-18 12:12 slideflow/sample_actions.py
 -rw-rw-r--  2.0 unx     1195 b- defN 23-Apr-09 06:29 slideflow/biscuit/__init__.py
@@ -159,16 +159,16 @@
 -rw-rw-r--  2.0 unx     9918 b- defN 23-Apr-09 06:29 slideflow/io/io_utils.py
 -rw-rw-r--  2.0 unx    34511 b- defN 23-Apr-09 06:29 slideflow/io/tensorflow.py
 -rw-rw-r--  2.0 unx    44556 b- defN 23-Apr-09 06:29 slideflow/io/torch.py
 -rw-rw-r--  2.0 unx       68 b- defN 23-Mar-13 02:04 slideflow/io/preservedsite/__init__.py
 -rw-rw-r--  2.0 unx     8419 b- defN 23-Mar-13 02:04 slideflow/io/preservedsite/crossfolds.py
 -rw-rw-r--  2.0 unx      284 b- defN 23-Apr-09 06:29 slideflow/mil/__init__.py
 -rw-rw-r--  2.0 unx    14819 b- defN 23-Apr-09 06:29 slideflow/mil/_params.py
--rw-rw-r--  2.0 unx     5231 b- defN 23-Apr-09 06:29 slideflow/mil/data.py
--rw-rw-r--  2.0 unx    15323 b- defN 23-Apr-12 04:31 slideflow/mil/eval.py
+-rw-rw-r--  2.0 unx     5160 b- defN 23-Apr-14 13:28 slideflow/mil/data.py
+-rw-rw-r--  2.0 unx    15565 b- defN 23-Apr-17 18:21 slideflow/mil/eval.py
 -rw-rw-r--  2.0 unx     3890 b- defN 23-Apr-09 06:29 slideflow/mil/clam/__init__.py
 -rw-rw-r--  2.0 unx     4334 b- defN 23-Apr-09 06:29 slideflow/mil/clam/create_attention.py
 -rw-rw-r--  2.0 unx     1131 b- defN 23-Apr-09 06:29 slideflow/mil/clam/datasets/__init__.py
 -rw-rw-r--  2.0 unx    14990 b- defN 23-Apr-09 06:29 slideflow/mil/clam/datasets/dataset_generic.py
 -rw-rw-r--  2.0 unx     5914 b- defN 23-Apr-09 06:29 slideflow/mil/clam/utils/__init__.py
 -rw-rw-r--  2.0 unx    19782 b- defN 23-Apr-09 06:29 slideflow/mil/clam/utils/core_utils.py
 -rw-rw-r--  2.0 unx     4150 b- defN 23-Apr-09 06:29 slideflow/mil/clam/utils/eval_utils.py
@@ -181,19 +181,19 @@
 -rw-rw-r--  2.0 unx     3607 b- defN 23-Apr-09 06:29 slideflow/mil/models/mil_fc.py
 -rw-rw-r--  2.0 unx     4137 b- defN 23-Apr-09 06:29 slideflow/mil/models/transmil.py
 -rw-rw-r--  2.0 unx    15008 b- defN 23-Apr-12 04:31 slideflow/mil/train/__init__.py
 -rw-rw-r--  2.0 unx     8214 b- defN 23-Apr-12 04:31 slideflow/mil/train/_fastai.py
 -rw-rw-r--  2.0 unx     7795 b- defN 23-Apr-09 06:29 slideflow/mil/train/_legacy.py
 -rw-rw-r--  2.0 unx     7485 b- defN 23-Apr-09 06:29 slideflow/model/__init__.py
 -rw-rw-r--  2.0 unx     1879 b- defN 23-Mar-13 02:04 slideflow/model/adv_utils.py
--rw-rw-r--  2.0 unx    23588 b- defN 23-Apr-09 06:29 slideflow/model/base.py
--rw-rw-r--  2.0 unx    55187 b- defN 23-Apr-10 23:12 slideflow/model/features.py
--rw-rw-r--  2.0 unx   110777 b- defN 23-Apr-09 06:29 slideflow/model/tensorflow.py
+-rw-rw-r--  2.0 unx    23588 b- defN 23-Apr-13 19:18 slideflow/model/base.py
+-rw-rw-r--  2.0 unx    55263 b- defN 23-Apr-17 18:21 slideflow/model/features.py
+-rw-rw-r--  2.0 unx   110908 b- defN 23-Apr-14 13:28 slideflow/model/tensorflow.py
 -rw-rw-r--  2.0 unx    22547 b- defN 23-Apr-03 05:27 slideflow/model/tensorflow_utils.py
--rw-rw-r--  2.0 unx   103048 b- defN 23-Apr-11 21:54 slideflow/model/torch.py
+-rw-rw-r--  2.0 unx   103179 b- defN 23-Apr-14 13:28 slideflow/model/torch.py
 -rw-rw-r--  2.0 unx    16945 b- defN 23-Apr-09 06:29 slideflow/model/torch_utils.py
 -rw-rw-r--  2.0 unx      394 b- defN 23-Apr-09 06:29 slideflow/model/extractors/__init__.py
 -rw-rw-r--  2.0 unx     3708 b- defN 23-Apr-09 06:29 slideflow/model/extractors/_factory.py
 -rw-rw-r--  2.0 unx     4544 b- defN 23-Apr-09 06:29 slideflow/model/extractors/_factory_tensorflow.py
 -rw-rw-r--  2.0 unx     5711 b- defN 23-Apr-09 06:29 slideflow/model/extractors/_factory_torch.py
 -rw-rw-r--  2.0 unx     1570 b- defN 23-Apr-09 06:29 slideflow/model/extractors/_registry.py
 -rw-rw-r--  2.0 unx     2646 b- defN 23-Apr-09 06:29 slideflow/model/extractors/_slide.py
@@ -215,33 +215,33 @@
 -rw-rw-r--  2.0 unx     7826 b- defN 22-Aug-06 13:13 slideflow/norm/torch/color.py
 -rw-rw-r--  2.0 unx    14869 b- defN 23-Apr-09 06:29 slideflow/norm/torch/macenko.py
 -rw-rw-r--  2.0 unx    24997 b- defN 23-Apr-09 06:29 slideflow/norm/torch/reinhard.py
 -rw-rw-r--  2.0 unx     1673 b- defN 23-Apr-09 06:29 slideflow/norm/torch/utils.py
 -rw-rw-r--  2.0 unx      458 b- defN 23-Mar-13 02:04 slideflow/simclr/__init__.py
 -rw-rw-r--  2.0 unx        6 b- defN 23-Feb-07 02:07 slideflow/simclr/simclr/__init__.py
 -rw-rw-r--  2.0 unx    20637 b- defN 23-Feb-15 14:12 slideflow/simclr/simclr/tf2/__init__.py
--rw-rw-r--  2.0 unx    10131 b- defN 23-Feb-06 18:28 slideflow/simclr/simclr/tf2/data.py
+-rw-rw-r--  2.0 unx    10701 b- defN 23-Apr-17 17:52 slideflow/simclr/simclr/tf2/data.py
 -rw-rw-r--  2.0 unx    18550 b- defN 23-Feb-03 23:00 slideflow/simclr/simclr/tf2/data_util.py
--rw-rw-r--  2.0 unx     6315 b- defN 23-Jan-23 19:16 slideflow/simclr/simclr/tf2/lars_optimizer.py
+-rw-rw-r--  2.0 unx     6505 b- defN 23-Apr-17 18:03 slideflow/simclr/simclr/tf2/lars_optimizer.py
 -rw-rw-r--  2.0 unx     2997 b- defN 23-Jan-23 19:16 slideflow/simclr/simclr/tf2/metrics.py
 -rw-rw-r--  2.0 unx    12256 b- defN 23-Feb-03 23:00 slideflow/simclr/simclr/tf2/model.py
 -rw-rw-r--  2.0 unx     4983 b- defN 23-Jan-23 19:16 slideflow/simclr/simclr/tf2/objective.py
 -rw-rw-r--  2.0 unx    28397 b- defN 23-Feb-03 23:00 slideflow/simclr/simclr/tf2/resnet.py
 -rw-rw-r--  2.0 unx     6524 b- defN 23-Feb-03 23:00 slideflow/simclr/simclr/tf2/run.py
 -rw-rw-r--  2.0 unx     9517 b- defN 23-Feb-06 18:24 slideflow/simclr/simclr/tf2/utils.py
--rw-rw-r--  2.0 unx   111594 b- defN 23-Apr-11 19:17 slideflow/slide/__init__.py
+-rw-rw-r--  2.0 unx   114638 b- defN 23-Apr-17 18:06 slideflow/slide/__init__.py
 -rw-rw-r--  2.0 unx    19045 b- defN 23-Apr-09 06:29 slideflow/slide/report.py
 -rw-rw-r--  2.0 unx    30934 b- defN 23-Apr-09 06:29 slideflow/slide/slideflow-logo-name-small.jpg
 -rw-rw-r--  2.0 unx     5516 b- defN 23-Apr-10 16:45 slideflow/slide/utils.py
 -rw-rw-r--  2.0 unx      708 b- defN 23-Mar-01 23:20 slideflow/slide/backends/__init__.py
 -rw-rw-r--  2.0 unx    14008 b- defN 23-Apr-09 06:29 slideflow/slide/backends/cucim.py
--rw-rw-r--  2.0 unx    22391 b- defN 23-Apr-09 06:29 slideflow/slide/backends/vips.py
+-rw-rw-r--  2.0 unx    22391 b- defN 23-Apr-13 22:48 slideflow/slide/backends/vips.py
 -rw-rw-r--  2.0 unx      117 b- defN 23-Mar-13 02:04 slideflow/slide/qc/__init__.py
 -rw-rw-r--  2.0 unx     1010 b- defN 22-Nov-29 16:52 slideflow/slide/qc/deepfocus_qc.py
--rw-rw-r--  2.0 unx     4304 b- defN 23-Apr-09 06:29 slideflow/slide/qc/gaussian.py
+-rw-rw-r--  2.0 unx     4304 b- defN 23-Apr-14 15:00 slideflow/slide/qc/gaussian.py
 -rw-rw-r--  2.0 unx     5232 b- defN 23-Apr-09 06:29 slideflow/slide/qc/otsu.py
 -rw-rw-r--  2.0 unx     3028 b- defN 23-Mar-13 02:04 slideflow/slide/qc/saver.py
 -rw-rw-r--  2.0 unx     4676 b- defN 23-Mar-13 02:04 slideflow/slide/qc/strided_dl.py
 -rw-rw-r--  2.0 unx      390 b- defN 23-Feb-01 21:02 slideflow/stats/__init__.py
 -rw-rw-r--  2.0 unx     4293 b- defN 23-Apr-09 06:29 slideflow/stats/delong.py
 -rw-rw-r--  2.0 unx    35785 b- defN 23-Apr-09 06:29 slideflow/stats/metrics.py
 -rw-rw-r--  2.0 unx     5757 b- defN 23-Apr-09 06:29 slideflow/stats/plot.py
@@ -312,26 +312,26 @@
 -rw-rw-r--  2.0 unx     7874 b- defN 23-Apr-09 06:29 slideflow/studio/gui/viewer/_mosaic.py
 -rw-rw-r--  2.0 unx    24818 b- defN 23-Apr-09 06:29 slideflow/studio/gui/viewer/_slide.py
 -rw-rw-r--  2.0 unx    14452 b- defN 23-Apr-09 06:29 slideflow/studio/gui/viewer/_viewer.py
 -rw-rw-r--  2.0 unx      439 b- defN 23-Apr-09 06:29 slideflow/studio/widgets/__init__.py
 -rw-rw-r--  2.0 unx      735 b- defN 23-Apr-09 06:29 slideflow/studio/widgets/_utils.py
 -rw-rw-r--  2.0 unx     4264 b- defN 23-Apr-09 06:29 slideflow/studio/widgets/capture.py
 -rw-rw-r--  2.0 unx     5412 b- defN 23-Apr-09 06:29 slideflow/studio/widgets/extensions.py
--rw-rw-r--  2.0 unx    17013 b- defN 23-Apr-09 06:29 slideflow/studio/widgets/heatmap.py
+-rw-rw-r--  2.0 unx    16890 b- defN 23-Apr-14 13:28 slideflow/studio/widgets/heatmap.py
 -rw-rw-r--  2.0 unx     3842 b- defN 23-Apr-09 06:29 slideflow/studio/widgets/layer_umap.py
 -rw-rw-r--  2.0 unx    24474 b- defN 23-Apr-09 06:29 slideflow/studio/widgets/model.py
 -rw-rw-r--  2.0 unx    14307 b- defN 23-Apr-09 06:29 slideflow/studio/widgets/mosaic.py
 -rw-rw-r--  2.0 unx     2597 b- defN 23-Mar-19 15:05 slideflow/studio/widgets/mosaic_experimental.py
 -rw-rw-r--  2.0 unx     4662 b- defN 23-Apr-09 06:29 slideflow/studio/widgets/performance.py
 -rw-rw-r--  2.0 unx     6437 b- defN 23-Apr-09 06:29 slideflow/studio/widgets/picam.py
 -rw-rw-r--  2.0 unx     7726 b- defN 23-Apr-09 06:29 slideflow/studio/widgets/project.py
 -rw-rw-r--  2.0 unx     5983 b- defN 23-Apr-09 06:29 slideflow/studio/widgets/seed_map.py
 -rw-rw-r--  2.0 unx    19875 b- defN 23-Apr-09 06:29 slideflow/studio/widgets/segment.py
 -rw-rw-r--  2.0 unx     2071 b- defN 23-Apr-09 06:29 slideflow/studio/widgets/settings.py
--rw-rw-r--  2.0 unx    31074 b- defN 23-Apr-09 06:29 slideflow/studio/widgets/slide.py
+-rw-rw-r--  2.0 unx    31018 b- defN 23-Apr-14 13:28 slideflow/studio/widgets/slide.py
 -rw-rw-r--  2.0 unx    16402 b- defN 23-Apr-09 06:29 slideflow/studio/widgets/stylegan.py
 -rw-rw-r--  2.0 unx    32309 b- defN 23-Apr-09 06:29 slideflow/test/__init__.py
 -rw-rw-r--  2.0 unx    12446 b- defN 23-Feb-01 21:02 slideflow/test/dataset_test.py
 -rw-rw-r--  2.0 unx     9560 b- defN 23-Mar-26 19:33 slideflow/test/functional.py
 -rw-rw-r--  2.0 unx     8052 b- defN 23-Apr-09 06:29 slideflow/test/model_test.py
 -rw-rw-r--  2.0 unx    12098 b- defN 23-Mar-01 23:20 slideflow/test/norm_test.py
 -rw-rw-r--  2.0 unx     2909 b- defN 23-Apr-09 06:29 slideflow/test/slide_test.py
@@ -340,22 +340,22 @@
 -rw-rw-r--  2.0 unx      891 b- defN 23-Mar-13 02:04 slideflow/tfrecord/__init__.py
 -rw-rw-r--  2.0 unx     2905 b- defN 22-Dec-02 04:52 slideflow/tfrecord/iterator_utils.py
 -rw-rw-r--  2.0 unx    15505 b- defN 23-Jan-29 22:26 slideflow/tfrecord/reader.py
 -rw-rw-r--  2.0 unx     5637 b- defN 22-Jul-18 12:12 slideflow/tfrecord/writer.py
 -rw-rw-r--  2.0 unx      179 b- defN 22-Jul-18 12:12 slideflow/tfrecord/tools/__init__.py
 -rw-rw-r--  2.0 unx      310 b- defN 22-Jul-18 12:12 slideflow/tfrecord/torch/__init__.py
 -rw-rw-r--  2.0 unx     7857 b- defN 22-Jul-18 12:12 slideflow/tfrecord/torch/dataset.py
--rw-rw-r--  2.0 unx    41104 b- defN 23-Apr-09 06:29 slideflow/util/__init__.py
+-rw-rw-r--  2.0 unx    41104 b- defN 23-Apr-13 22:11 slideflow/util/__init__.py
 -rw-rw-r--  2.0 unx      738 b- defN 22-Jul-15 00:02 slideflow/util/colors.py
 -rw-rw-r--  2.0 unx    17912 b- defN 22-Jul-18 12:12 slideflow/util/example_pb2.py
 -rw-rw-r--  2.0 unx     4468 b- defN 23-Feb-01 21:02 slideflow/util/log_utils.py
 -rw-rw-r--  2.0 unx     4381 b- defN 22-Jul-18 12:12 slideflow/util/neptune_utils.py
 -rw-rw-r--  2.0 unx    20061 b- defN 23-Apr-09 06:29 slideflow/util/smac_utils.py
--rw-rw-r--  2.0 unx     7920 b- defN 23-Apr-12 04:31 slideflow/util/tfrecord2idx.py
--rwxrwxr-x  2.0 unx    14085 b- defN 23-Apr-12 04:31 slideflow-2.0.1.data/scripts/slideflow-studio
--rwxrwxr-x  2.0 unx    14085 b- defN 23-Apr-10 13:18 slideflow-2.0.1.data/scripts/slideflow-studio.py
--rw-rw-r--  2.0 unx    35149 b- defN 23-Apr-12 04:31 slideflow-2.0.1.dist-info/LICENSE
--rw-rw-r--  2.0 unx    12998 b- defN 23-Apr-12 04:31 slideflow-2.0.1.dist-info/METADATA
--rw-rw-r--  2.0 unx       92 b- defN 23-Apr-12 04:31 slideflow-2.0.1.dist-info/WHEEL
--rw-rw-r--  2.0 unx       10 b- defN 23-Apr-12 04:31 slideflow-2.0.1.dist-info/top_level.txt
-?rw-rw-r--  2.0 unx    35648 b- defN 23-Apr-12 04:31 slideflow-2.0.1.dist-info/RECORD
-359 files, 4764377 bytes uncompressed, 1779382 bytes compressed:  62.7%
+-rw-rw-r--  2.0 unx     8046 b- defN 23-Apr-17 18:21 slideflow/util/tfrecord2idx.py
+-rwxrwxr-x  2.0 unx    14085 b- defN 23-Apr-17 18:28 slideflow-2.0.2.data/scripts/slideflow-studio
+-rwxrwxr-x  2.0 unx    14085 b- defN 23-Apr-10 13:18 slideflow-2.0.2.data/scripts/slideflow-studio.py
+-rw-rw-r--  2.0 unx    35149 b- defN 23-Apr-17 18:28 slideflow-2.0.2.dist-info/LICENSE
+-rw-rw-r--  2.0 unx    12998 b- defN 23-Apr-17 18:28 slideflow-2.0.2.dist-info/METADATA
+-rw-rw-r--  2.0 unx       92 b- defN 23-Apr-17 18:28 slideflow-2.0.2.dist-info/WHEEL
+-rw-rw-r--  2.0 unx       10 b- defN 23-Apr-17 18:28 slideflow-2.0.2.dist-info/top_level.txt
+?rw-rw-r--  2.0 unx    35648 b- defN 23-Apr-17 18:28 slideflow-2.0.2.dist-info/RECORD
+359 files, 4768722 bytes uncompressed, 1780521 bytes compressed:  62.7%
```

## zipnote {}

```diff
@@ -1050,29 +1050,29 @@
 
 Filename: slideflow/util/smac_utils.py
 Comment: 
 
 Filename: slideflow/util/tfrecord2idx.py
 Comment: 
 
-Filename: slideflow-2.0.1.data/scripts/slideflow-studio
+Filename: slideflow-2.0.2.data/scripts/slideflow-studio
 Comment: 
 
-Filename: slideflow-2.0.1.data/scripts/slideflow-studio.py
+Filename: slideflow-2.0.2.data/scripts/slideflow-studio.py
 Comment: 
 
-Filename: slideflow-2.0.1.dist-info/LICENSE
+Filename: slideflow-2.0.2.dist-info/LICENSE
 Comment: 
 
-Filename: slideflow-2.0.1.dist-info/METADATA
+Filename: slideflow-2.0.2.dist-info/METADATA
 Comment: 
 
-Filename: slideflow-2.0.1.dist-info/WHEEL
+Filename: slideflow-2.0.2.dist-info/WHEEL
 Comment: 
 
-Filename: slideflow-2.0.1.dist-info/top_level.txt
+Filename: slideflow-2.0.2.dist-info/top_level.txt
 Comment: 
 
-Filename: slideflow-2.0.1.dist-info/RECORD
+Filename: slideflow-2.0.2.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## slideflow/_version.py

```diff
@@ -4,18 +4,18 @@
 # unpacked source archive. Distribution tarballs contain a pre-generated copy
 # of this file.
 
 import json
 
 version_json = '''
 {
- "date": "2023-04-11T23:17:03-0500",
+ "date": "2023-04-17T13:21:28-0500",
  "dirty": false,
  "error": null,
- "full-revisionid": "3495a878316e9e6ba4525c3a225827817f5198e9",
- "version": "2.0.1"
+ "full-revisionid": "204a302fa0942fc84b611828b43f4412761e33cd",
+ "version": "2.0.2"
 }
 '''  # END VERSION_JSON
 
 
 def get_versions():
     return json.loads(version_json)
```

## slideflow/dataset.py

```diff
@@ -1437,19 +1437,20 @@
                 JPG (lossy) for efficiency.
             full_core (bool, optional): Only used if extracting from TMA.
                 If True, will save entire TMA core as image.
                 Otherwise, will extract sub-images from each core using the
                 given tile micron size. Defaults to False.
             shuffle (bool, optional): Shuffle tiles prior to storage in
                 tfrecords. Defaults to True.
-            num_threads (int, optional): Number of workers threads for each
+            num_threads (int, optional): Number of worker processes for each
                 tile extractor. When using cuCIM slide reading backend,
-                defaults to the total number of available CPU threads.
-                With Libvips, this defaults to the total number of available
-                CPU threads or 32, whichever is lower.
+                defaults to the total number of available CPU cores, using the
+                'fork' multiprocessing method. With Libvips, this defaults to
+                the total number of available CPU cores or 32, whichever is
+                lower, using 'spawn' multiprocessing.
             qc_blur_radius (int, optional): Quality control blur radius for
                 out-of-focus area detection. Used if qc=True. Defaults to 3.
             qc_blur_threshold (float, optional): Quality control blur threshold
                 for detecting out-of-focus areas. Only used if qc=True.
                 Defaults to 0.1
             qc_filter_threshold (float, optional): Float between 0-1. Tiles
                 with more than this proportion of blur will be discarded.
```

## slideflow/mil/data.py

```diff
@@ -1,12 +1,11 @@
 """Dataset utility functions for MIL."""
 
 from dataclasses import dataclass
-from collections.abc import Sequence
-from typing import Any, Iterable, Optional, Tuple, Callable, Union, Protocol
+from typing import Any, List, Optional, Tuple, Callable, Union, Protocol
 from pathlib import Path
 
 import numpy as np
 import numpy.typing as npt
 import torch
 from torch.utils.data import Dataset
 
@@ -61,15 +60,15 @@
 
 # -----------------------------------------------------------------------------
 
 @dataclass
 class BagDataset(Dataset):
     """A dataset of bags of instances."""
 
-    bags: Sequence[Iterable[Path]]
+    bags: List[Path]
     """The `.h5` files containing the bags.
     Each bag consists of the features taken from one or multiple h5 files.
     Each of the h5 files needs to have a dataset called `feats` of shape N x
     F, where N is the number of instances and F the number of features per
     instance.
     """
     bag_size: Optional[int] = None
@@ -132,17 +131,17 @@
         return self
 
 # -----------------------------------------------------------------------------
 
 class SKLearnEncoder(Protocol):
     """An sklearn-style encoder."""
 
-    categories_: Sequence[Sequence[str]]
+    categories_: List[List[str]]
 
-    def transform(self, x: Sequence[Sequence[Any]]):
+    def transform(self, x: List[List[Any]]):
         ...
 
 
 # -----------------------------------------------------------------------------
 
 class EncodedDataset(MapDataset):
     def __init__(self, encode: SKLearnEncoder, values: npt.NDArray):
```

## slideflow/mil/eval.py

```diff
@@ -153,16 +153,21 @@
 
     # Export attention
     if y_att:
         att_path = join(model_dir, 'attention')
         if not exists(att_path):
             os.makedirs(att_path)
         for slide, att in zip(slides, y_att):
-            np.savez(join(att_path, f'{slide}_att.npz'), att)
-        log.info(f"Attention scores exported to [green]{att_path}[/]")
+            if 'SF_ALLOW_ZIP' in os.environ and os.environ['SF_ALLOW_ZIP'] == '0':
+                out_path = join(att_path, f'{slide}_att.npy')
+                np.save(out_path, att)
+            else:
+                out_path = join(att_path, f'{slide}_att.npz')
+                np.savez(out_path, att)
+        log.info(f"Attention scores exported to [green]{out_path}[/]")
 
     # Attention heatmaps
     if y_att and attention_heatmaps:
         generate_attention_heatmaps(
             outdir=join(model_dir, 'heatmaps'),
             dataset=dataset,
             bags=bags,
```

## slideflow/model/features.py

```diff
@@ -16,15 +16,15 @@
 
 import numpy as np
 import pandas as pd
 import scipy.stats as stats
 import slideflow as sf
 from rich.progress import track, Progress
 from slideflow import errors
-from slideflow.util import log, Labels, ImgBatchSpeedColumn
+from slideflow.util import log, Labels, ImgBatchSpeedColumn, tfrecord2idx
 from .base import BaseFeatureExtractor
 
 
 if TYPE_CHECKING:
     import tensorflow as tf
     import torch
 
@@ -534,29 +534,33 @@
     ) -> None:
         """Export activations in torch format to .pt files in the directory.
 
         Used for training MIL models.
 
         Args:
             outdir (str): Path to directory in which to save .pt files.
-        """
 
+        """
         import torch
+
         if not exists(outdir):
             os.makedirs(outdir)
         slides = self.slides if not slides else slides
         for slide in track(slides):
             if self.activations[slide] == []:
                 log.info(f'Skipping empty slide [green]{slide}')
                 continue
             slide_activations = torch.from_numpy(
                 self.activations[slide].astype(np.float32)
             )
             torch.save(slide_activations, join(outdir, f'{slide}.pt'))
-            np.savez(join(outdir, f'{slide}.index'), self.locations[slide])
+            tfrecord2idx.save_index(
+                self.locations[slide],
+                join(outdir, f'{slide}.index')
+            )
         args = {
             'model': self.model if isinstance(self.model, str) else '<NA>',
             'num_features': self.num_features
         }
         sf.util.write_json(args, join(outdir, 'settings.json'))
         log.info(f'Activations exported in Torch format to {outdir}')
```

## slideflow/model/tensorflow.py

```diff
@@ -2234,16 +2234,20 @@
 
     def __call__(
         self,
         inp: Union[tf.Tensor, "sf.WSI"],
         **kwargs
     ) -> Optional[Union[np.ndarray, tf.Tensor]]:
         """Process a given input and return features and/or predictions.
-        Expects either a batch of images or a :class:`slideflow.WSI`."""
+        Expects either a batch of images or a :class:`slideflow.WSI`.
 
+        When calling on a `WSI` object, keyword arguments are passed to
+        :meth:`slideflow.WSI.build_generator()`.
+
+        """
         if isinstance(inp, sf.WSI):
             return self._predict_slide(inp, **kwargs)
         else:
             return self._predict(inp)
 
     def _predict_slide(
         self,
```

## slideflow/model/torch.py

```diff
@@ -2077,16 +2077,20 @@
 
     def __call__(
         self,
         inp: Union[Tensor, "sf.WSI"],
         **kwargs
     ) -> Optional[Union[List[Tensor], np.ndarray]]:
         """Process a given input and return activations and/or predictions. Expects
-        either a batch of images or a :class:`slideflow.slide.WSI` object."""
+        either a batch of images or a :class:`slideflow.slide.WSI` object.
 
+        When calling on a `WSI` object, keyword arguments are passed to
+        :meth:`slideflow.WSI.build_generator()`.
+
+        """
         if isinstance(inp, sf.slide.WSI):
             return self._predict_slide(inp, **kwargs)
         else:
             return self._predict(inp, **kwargs)
 
     def _predict_slide(
         self,
```

## slideflow/simclr/simclr/tf2/data.py

```diff
@@ -181,15 +181,15 @@
         for _ in range(2):  # Two transformations
           xs.append(preprocess_fn_pretrain(image))
         image = tf.concat(xs, -1)
       else:
         image = preprocess_fn_finetune(image)
       if num_classes:
         label = tf.one_hot(label, num_classes)
-      return image, label, *args
+      return detuple(image, label, args)
 
     logging.info('num_input_pipelines: %d', input_context.num_input_pipelines)
     dataset = builder.as_dataset(
         split=simclr_args.train_split if is_training else simclr_args.eval_split,
         shuffle_files=is_training,
         as_supervised=True,
         # Passing the input_context to TFDS makes TFDS read different parts
@@ -239,7 +239,30 @@
       data_util.preprocess_image,
       height=image_size,
       width=image_size,
       color_jitter_strength=color_jitter_strength,
       is_training=is_training,
       color_distort=is_pretrain,
       test_crop=test_crop)
+
+# -----------------------------------------------------------------------------
+
+def detuple(image, label, args):
+    """Detuple optional arguments for return.
+
+    Adds support for returning args via wildcard in Python 3.7. The following:
+
+    .. code-block:: python
+
+        return image, label, *args
+
+    can be made cross-compatible with Python 3.7 and higher by using:
+
+    .. code-block:: python
+
+        return detuple(image, label, args)
+
+    """
+    if len(args):
+        return tuple([image, label] + list(args))
+    else:
+        return image, label
```

## slideflow/simclr/simclr/tf2/lars_optimizer.py

```diff
@@ -14,19 +14,25 @@
 # limitations under the License.
 # ==============================================================================
 """Functions and classes related to optimization (weight updates)."""
 
 import re
 
 import tensorflow.compat.v2 as tf
+from packaging import version
+
+if version.parse(tf.__version__) > version.parse("2.10"):
+    from tensorflow.keras.optimizers.legacy import Optimizer
+else:
+    from tensorflow.keras.optimizers import Optimizer
 
 EETA_DEFAULT = 0.001
 
 
-class LARSOptimizer(tf.keras.optimizers.Optimizer):
+class LARSOptimizer(Optimizer):
   """Layer-wise Adaptive Rate Scaling for large batch training.
 
   Introduced by "Large Batch Training of Convolutional Networks" by Y. You,
   I. Gitman, and B. Ginsburg. (https://arxiv.org/abs/1708.03888)
   """
 
   def __init__(self,
```

## slideflow/slide/__init__.py

```diff
@@ -568,31 +568,33 @@
         width: Optional[int] = None,
         coords: Optional[List[int]] = None,
         rect_linewidth: int = 2,
         rect_color: str = 'black',
         use_associated_image: bool = False,
         low_res: bool = False
     ) -> Image.Image:
-        '''Returns PIL thumbnail of the slide.
+        """Returns PIL thumbnail of the slide.
 
         Args:
             mpp (float, optional): Microns-per-pixel, used to determine
                 thumbnail size.
             width (int, optional): Alternatively, goal thumbnail width
                 may be supplied.
             coords (list(int), optional): List of tile extraction coordinates
                 to show as rectangles on the thumbnail, in [(x_center,
                 y_center), ...] format. Defaults to None.
             use_associated_image (bool): Use the associated thumbnail image
                 in the slide, rather than reading from a pyramid layer.
+            low_res (bool): Create thumbnail from the lowest-mangnification
+                pyramid layer. Defaults to False.
 
         Returns:
             PIL image
-        '''
 
+        """
         # If no values provided, create thumbnail of width 1024
         if mpp is None and width is None:
             width = 1024
         if (mpp is not None and width is not None):
             raise ValueError(
                 "Either mpp or width must be given, but not both"
                 f" (got mpp={mpp}, width={width})"
@@ -606,20 +608,23 @@
         else:
             assert width is not None
             mpp = (self.mpp * self.dimensions[0]) / width
         # Calculate appropriate height
         height = int((self.mpp * self.dimensions[1]) / mpp)
 
         if use_associated_image:
+            log.debug("Requesting thumbnail using associated image")
             thumb_kw = dict(associated='thumbnail')
         elif low_res:
+            log.debug("Requesting thumbnail at level={}, width={}".format(level, width))
             thumb_kw = dict(level=self.slide.level_count-1, width=width)
         else:
             ds = self.dimensions[0] / width
             level = self.slide.best_level_for_downsample(ds)
+            log.debug("Requesting thumbnail at level={}, width={}".format(level, width))
             thumb_kw = dict(level=level, width=width)
 
         np_thumb = self.slide.thumbnail(**thumb_kw)
         image = Image.fromarray(np_thumb).resize((width, height))
 
         if coords:
             draw = ImageDraw.Draw(image)
@@ -648,14 +653,15 @@
         img_format: str = 'numpy',
         full_core: bool = False,
         yolo: bool = False,
         draw_roi: bool = False,
         pool: Optional["mp.pool.Pool"] = None,
         dry_run: bool = False
     ) -> Optional[Callable]:
+        """Build a tile generator."""
         lead_msg = f'Extracting {self.tile_um}um tiles'
         if self.extract_px != self.tile_px:
             resize_msg = f'(resizing {self.extract_px}px -> {self.tile_px}px)'
         else:
             resize_msg = f'({self.extract_px}px, not resizing)'
         stride_msg = f'stride: {int(self.stride)}px'
         log.debug(f"{self.shortname}: {lead_msg} {resize_msg}; {stride_msg}")
@@ -710,14 +716,24 @@
             yolo (bool, optional): Export yolo-formatted tile-level ROI
                 annotations (.txt) in the tile directory. Requires that
                 tiles_dir is set. Defaults to False.
             draw_roi (bool, optional): Draws ROIs onto extracted tiles.
                 Defaults to False.
             dry_run (bool, optional): Determine tiles that would be extracted,
                 but do not export any images. Defaults to None.
+            num_threads (int): If specified, will extract tiles with a
+                ThreadPool using the specified number of threads. Cannot
+                supply both `num_threads` and `num_processes`. Libvips is
+                particularly slow with ThreadPools. Defaults to None in the
+                Libvips backend, and the number of CPU cores when using cuCIM.
+            num_processes (int): If specified, will extract tiles with a
+                multiprocessing pool using the specified number of processes.
+                Cannot supply both `num_threads` and `num_processes`.
+                With the libvips backend, this defaults to half the number of
+                CPU cores, and with cuCIM, this defaults to None.
         """
         if img_format not in ('png', 'jpg', 'jpeg'):
             raise ValueError(f"Invalid image format {img_format}")
 
         dry_run = kwargs['dry_run'] if 'dry_run' in kwargs else False
 
         # Make base directories
@@ -888,14 +904,15 @@
                 annotations (.txt) in the tile directory. Requires that
                 tiles_dir is set. Defaults to False.
         """
         if 'show_progress' not in kwargs:
             kwargs['show_progress'] = (self.pb is None)
         generator = self.build_generator(
             dry_run=True,
+            deterministic=False,
             **kwargs
         )
         if generator is None:
             return self.thumb(rois=rois, low_res=True)
         locations = []
         for tile_dict in generator():
             locations += [tile_dict['loc']]
@@ -1464,18 +1481,19 @@
         pool: Optional["mp.pool.Pool"] = None,
         dry_run: bool = False,
         lazy_iter: bool = False,
         shard: Optional[Tuple[int, int]] = None,
         max_tiles: Optional[int] = None,
         from_centroids: bool = False,
         apply_masks: bool = True,
+        deterministic: bool = True
     ) -> Optional[Callable]:
         """Builds tile generator to extract tiles from this slide.
 
-        Args:
+        Keyword args:
             shuffle (bool): Shuffle images during extraction.
             whitespace_fraction (float, optional): Range 0-1. Defaults to 1.
                 Discard tiles with this fraction of whitespace. If 1, will not
                 perform whitespace filtering.
             whitespace_threshold (int, optional): Range 0-255. Defaults to 230.
                 Threshold above which a pixel (RGB average) is whitespace.
             grayspace_fraction (float, optional): Range 0-1. Defaults to 0.6.
@@ -1489,14 +1507,24 @@
             normalizer_source (str, optional): Path to normalizer source image.
                 If None, will use slideflow.slide.norm_tile.jpg.
                 Defaults to None.
             context_normalize (bool): If normalizing, use context from
                 the rest of the slide when calculating stain matrix
                 concentrations. Defaults to False (normalize each image tile
                 as separate images).
+            num_threads (int): If specified, will extract tiles with a
+                ThreadPool using the specified number of threads. Cannot
+                supply both `num_threads` and `num_processes`. Libvips is
+                particularly slow with ThreadPools. Defaults to None in the
+                Libvips backend, and the number of CPU cores when using cuCIM.
+            num_processes (int): If specified, will extract tiles with a
+                multiprocessing pool using the specified number of processes.
+                Cannot supply both `num_threads` and `num_processes`.
+                With the libvips backend, this defaults to half the number of
+                CPU cores, and with cuCIM, this defaults to None.
             show_progress (bool, optional): Show a progress bar.
             img_format (str, optional): Image format. Either 'numpy', 'jpg',
                 or 'png'. Defaults to 'numpy'.
             yolo (bool, optional): Include yolo-formatted tile-level ROI
                 annotations in the return dictionary, under the key 'yolo'.
                 Defaults to False.
             draw_roi (bool, optional): Draws ROIs onto extracted tiles.
@@ -1508,14 +1536,17 @@
             from_centroids (bool): Extract tiles from cell segmentation
                 centroids, rather than in a grid-wise pattern. Requires that
                 cell segmentation has already been applied with
                 `WSI.apply_segmentation()`. Defaults to False.
             apply_masks (bool): Apply cell segmentation masks to tiles. Ignored
                 if cell segmentation has been applied to the slide.
                 Defaults to True.
+            deterministic (bool): Return tile images in reproducible,
+                deterministic order. May slightly decrease iteration time.
+                Defaults to True.
 
         Returns:
             dict: Dict with keys 'image' (image data), 'yolo' (optional
             yolo-formatted annotations, (x_center, y_center,
             width, height)) and 'grid' ((x, y) slide or grid coordinates)
 
         """
@@ -1608,15 +1639,15 @@
             'yolo': yolo,
             'draw_roi': draw_roi,
             'dry_run': dry_run,
             'has_segmentation': from_centroids
         })
 
         def generator():
-            nonlocal pool
+            nonlocal pool, num_threads, num_processes
             should_close = False
             n_extracted = 0
 
             # Skip tiles filtered out with QC or ROI
             if not from_centroids:
                 non_roi_coord = self.coord[
                     self.grid[tuple(self.coord[:, 2:4].T)].astype(bool)
@@ -1654,23 +1685,26 @@
                 shard_idx, shard_count = shard
                 sharded_coords = np.array_split(non_roi_coord, shard_count)
                 non_roi_coord = sharded_coords[shard_idx]
 
             # Set up worker pool
             if pool is None:
                 if num_threads is None and num_processes is None:
-                    # ThreadPool used by default due to escalating memory
-                    # requirements when using multiprocessing
-                    log.debug(f"Building generator ThreadPool({num_threads})")
-                    _threads = os.cpu_count() if os.cpu_count() else 8
-                    pool = mp.dummy.Pool(processes=_threads)
-                    should_close = True
-                elif num_threads is not None and num_threads > 1:
+                    # Libvips is extremely slow with ThreadPools.
+                    # In the cuCIM backend, ThreadPools are used by default
+                    # to reduce memory utilization.
+                    # In the Libvips backend, a multiprocessing pool is default
+                    # to significantly improve performance.
+                    n_cores = os.cpu_count() if os.cpu_count() else 8
+                    if sf.slide_backend() == 'libvips':
+                        num_processes = max(int(n_cores/2), 1)
+                    else:
+                        num_threads = n_cores
+                if num_threads is not None and num_threads > 1:
                     log.debug(f"Building generator ThreadPool({num_threads})")
-                    _threads = os.cpu_count() if os.cpu_count() else 8
                     pool = mp.dummy.Pool(processes=num_threads)
                     should_close = True
                 elif num_processes is not None and num_processes > 1:
                     log.debug(f"Building generator with Pool({num_processes})")
                     ctx = mp.get_context('spawn')
                     pool = ctx.Pool(
                         processes=num_processes,
@@ -1685,53 +1719,56 @@
                     i_mapped = _generator()
             else:
                 log.debug("Building generator with a shared pool")
             if show_progress:
                 pbar = Progress(transient=sf.getLoggingLevel() > 20)
                 task = pbar.add_task('Extracting...', total=self.estimated_num_tiles)
                 pbar.start()
+            else:
+                pbar = None
 
             if pool is not None:
+                map_fn = pool.imap if deterministic else pool.imap_unordered
                 if lazy_iter:
                     if max_tiles:
                         batch_size = min(pool._processes, max_tiles)
                     else:
                         batch_size = pool._processes
                     batched_coord = sf.util.batch(non_roi_coord, batch_size)
                     def _generator():
                         for batch in batched_coord:
-                            yield from pool.imap(
+                            yield from map_fn(
                                 partial(tile_worker, args=w_args),
                                 batch
                             )
                     i_mapped = _generator()
 
                 else:
                     csize = max(min(int(self.estimated_num_tiles/pool._processes), 64), 1)
                     log.debug(f"Using imap chunksize={csize}")
-                    i_mapped = pool.imap(
+                    i_mapped = map_fn(
                         partial(tile_worker, args=w_args),
                         non_roi_coord,
                         chunksize=csize
                     )
 
-            for e, result in enumerate(i_mapped):
-                if show_progress:
-                    pbar.advance(task, 1)
-                elif self.pb is not None:
-                    self.pb.advance(0)
-                if result is None:
-                    continue
-                else:
-                    yield result
-                    n_extracted += 1
-                    if max_tiles and n_extracted >= max_tiles:
-                        break
-            if show_progress:
-                pbar.stop()
+            with sf.util.cleanup_progress(pbar):
+                for e, result in enumerate(i_mapped):
+                    if show_progress:
+                        pbar.advance(task, 1)
+                    elif self.pb is not None:
+                        self.pb.advance(0)
+                    if result is None:
+                        continue
+                    else:
+                        yield result
+                        n_extracted += 1
+                        if max_tiles and n_extracted >= max_tiles:
+                            break
+
             if should_close:
                 pool.close()
 
             # Reset stain normalizer context
             if normalizer and context_normalize:
                 assert isinstance(normalizer, sf.norm.StainNormalizer)
                 normalizer.clear_context()
@@ -1762,19 +1799,23 @@
             width (int, optional): Goal thumbnail width (alternative to mpp).
             coords (list(int), optional): List of tile extraction coordinates
                 to show as rectangles on the thumbnail, in [(x_center,
                 y_center), ...] format. Defaults to None.
             rois (bool, optional): Draw ROIs onto thumbnail. Defaults to False.
             linewidth (int, optional): Width of ROI line. Defaults to 2.
             color (str, optional): Color of ROI. Defaults to black.
+            use_associated_image (bool): Use the associated thumbnail image
+                in the slide, rather than reading from a pyramid layer.
+            low_res (bool): Create thumbnail from the lowest-mangnification
+                pyramid layer. Defaults to False.
 
         Returns:
             PIL image
-        """
 
+        """
         if rois and len(self.rois):
             if (mpp is not None and width is not None):
                 raise ValueError(
                     "Either mpp or width must be given, but not both"
                     f" (got mpp={mpp}, width={width})"
                 )
             # If no values provided, create thumbnail of width 1024
@@ -2580,87 +2621,87 @@
             if show_progress:
                 pbar = Progress(transient=sf.getLoggingLevel()>20)
                 task = pbar.add_task(
                     "Extracting...",
                     total=self.estimated_num_tiles
                 )
                 pbar.start()
-            ctx = mp.get_context('spawn')
-            extraction_pool = ctx.Pool(
-                num_threads,
-                section_extraction_worker,
-                (rectangle_queue, extraction_queue,)
-            )
-            for rect in self.object_rects:
-                rectangle_queue.put(rect)
-            rectangle_queue.put((-1, "DONE"))
-
-            queue_progress = 0
-            while True:
-                queue_progress += 1
-                tile_id, image_core = extraction_queue.get()
-                if type(image_core) == str and image_core == "DONE":
-                    break
-                else:
-                    if self.pb:
-                        self.pb.advance(0)
-                    if show_progress:
-                        pbar.advance(task, 1)
-
-                    resized_core = self._resize_to_target(image_core)
-
-                    if full_core:
-                        resized = cv2.resize(
-                            image_core,
-                            (self.tile_px, self.tile_px)
-                        )
-                        # Convert to final image format
-                        if img_format != 'numpy':
-                            resized = _convert_img_to_format(
-                                resized,
-                                img_format
-                            )
-
-                        yield {'image': resized, 'loc': [0, 0]}
+            else:
+                pbar = None
+            with sf.util.cleanup_progress(pbar):
+                ctx = mp.get_context('spawn')
+                extraction_pool = ctx.Pool(
+                    num_threads,
+                    section_extraction_worker,
+                    (rectangle_queue, extraction_queue,)
+                )
+                for rect in self.object_rects:
+                    rectangle_queue.put(rect)
+                rectangle_queue.put((-1, "DONE"))
+
+                queue_progress = 0
+                while True:
+                    queue_progress += 1
+                    tile_id, image_core = extraction_queue.get()
+                    if type(image_core) == str and image_core == "DONE":
+                        break
                     else:
-                        subtiles = self._split_core(resized_core)
-                        for subtile in subtiles:
-                            # Perform whitespace filtering
-                            if whitespace_fraction < 1:
-                                frac = (np.mean(subtile, axis=2)
-                                        > whitespace_threshold).sum()
-                                frac = frac / (self.tile_px**2)
-                                if frac > whitespace_fraction:
-                                    continue
-
-                            # Perform grayspace filtering
-                            if grayspace_fraction < 1:
-                                hsv_image = mcol.rgb_to_hsv(subtile)
-                                frac = (hsv_image[:, :, 1]
-                                        < grayspace_threshold).sum()
-                                frac = frac / (self.tile_px**2)
-                                if frac > grayspace_fraction:
-                                    continue
-
-                            # Apply normalization
-                            if norm is not None:
-                                try:
-                                    subtile = norm.rgb_to_rgb(subtile)
-                                except Exception:
-                                    # The image could not be normalized, which
-                                    # happens when a tile is primarily one
-                                    # solid color (background)
-                                    continue
-
+                        if self.pb:
+                            self.pb.advance(0)
+                        if show_progress:
+                            pbar.advance(task, 1)
+
+                        resized_core = self._resize_to_target(image_core)
+
+                        if full_core:
+                            resized = cv2.resize(
+                                image_core,
+                                (self.tile_px, self.tile_px)
+                            )
                             # Convert to final image format
                             if img_format != 'numpy':
-                                subtile = _convert_img_to_format(
-                                    subtile,
+                                resized = _convert_img_to_format(
+                                    resized,
                                     img_format
                                 )
-                            yield {'image': subtile, 'loc': [0, 0]}
 
-            extraction_pool.close()
-            if show_progress:
-                pbar.stop()
+                            yield {'image': resized, 'loc': [0, 0]}
+                        else:
+                            subtiles = self._split_core(resized_core)
+                            for subtile in subtiles:
+                                # Perform whitespace filtering
+                                if whitespace_fraction < 1:
+                                    frac = (np.mean(subtile, axis=2)
+                                            > whitespace_threshold).sum()
+                                    frac = frac / (self.tile_px**2)
+                                    if frac > whitespace_fraction:
+                                        continue
+
+                                # Perform grayspace filtering
+                                if grayspace_fraction < 1:
+                                    hsv_image = mcol.rgb_to_hsv(subtile)
+                                    frac = (hsv_image[:, :, 1]
+                                            < grayspace_threshold).sum()
+                                    frac = frac / (self.tile_px**2)
+                                    if frac > grayspace_fraction:
+                                        continue
+
+                                # Apply normalization
+                                if norm is not None:
+                                    try:
+                                        subtile = norm.rgb_to_rgb(subtile)
+                                    except Exception:
+                                        # The image could not be normalized, which
+                                        # happens when a tile is primarily one
+                                        # solid color (background)
+                                        continue
+
+                                # Convert to final image format
+                                if img_format != 'numpy':
+                                    subtile = _convert_img_to_format(
+                                        subtile,
+                                        img_format
+                                    )
+                                yield {'image': subtile, 'loc': [0, 0]}
+                extraction_pool.close()
 
         return generator
```

## slideflow/studio/widgets/heatmap.py

```diff
@@ -52,20 +52,18 @@
         self._heatmap_toast         = None
         self._colormaps             = plt.colormaps()
         self._rendering_message     = "Calculating whole-slide prediction..."
 
     def _create_heatmap(self):
         viz = self.viz
         self.reset()
-        if sf.slide_backend() == 'cucim':
-            mp_kw = dict(num_threads=os.cpu_count())
-        else:
-            mp_kw = dict(num_processes=os.cpu_count())
         if viz.low_memory:
             mp_kw = dict(num_threads=1, batch_size=4)
+        else:
+            mp_kw = dict()
         if sf.util.model_backend(self.viz.model) == 'torch':
             mp_kw['apply_softmax'] = self.is_categorical()
         viz.heatmap = sf.heatmap.ModelHeatmap(
             viz.wsi,
             viz.model,
             img_format=viz._model_config['img_format'],
             generate=False,
```

## slideflow/studio/widgets/slide.py

```diff
@@ -90,17 +90,17 @@
 
     # --- Internal ------------------------------------------------------------
 
     def _filter_thread_worker(self):
         if self.viz.wsi is not None:
             self.viz.set_message(self._rendering_message)
             if self.viz.low_memory or sf.slide_backend() == 'cucim':
-                mp_kw = dict(num_threads=os.cpu_count(), lazy_iter=True)
+                mp_kw = dict(lazy_iter=True)
             else:
-                mp_kw = dict(num_processes=os.cpu_count())
+                mp_kw = dict()
             generator = self.viz.wsi.build_generator(
                 img_format='numpy',
                 grayspace_fraction=sf.slide.FORCE_CALCULATE_GRAYSPACE,
                 grayspace_threshold=self.gs_threshold,
                 whitespace_fraction=sf.slide.FORCE_CALCULATE_WHITESPACE,
                 whitespace_threshold=self.ws_threshold,
                 shuffle=False,
```

## slideflow/util/tfrecord2idx.py

```diff
@@ -55,19 +55,23 @@
             infile.read(proto_len)
             infile.read(4)
             out_array += [[cur, infile.tell() - cur]]
         except Exception:
             print("Failed to parse TFRecord.")
             break
     infile.close()
-    out_array = np.array(out_array)
+    save_index(np.array(out_array), index_file)
+
+
+def save_index(index_array: np.ndarray, index_file: str) -> None:
+    """Save an array as an index file."""
     if 'SF_ALLOW_ZIP' in os.environ and os.environ['SF_ALLOW_ZIP'] == '0':
-        np.save(index_file + '.npy', out_array)
+        np.save(index_file + '.npy', index_array)
     else:
-        np.savez(index_file, out_array)
+        np.savez(index_file, index_array)
 
 
 def find_index(tfrecord: str) -> Optional[str]:
     name = sf.util.path_to_name(tfrecord)
     if exists(join(dirname(tfrecord), name+'.index')):
         return join(dirname(tfrecord), name+'.index')
     elif exists(join(dirname(tfrecord), name+'.index.npz')):
```

## Comparing `slideflow-2.0.1.data/scripts/slideflow-studio` & `slideflow-2.0.2.data/scripts/slideflow-studio.py`

 * *Files identical despite different names*

## Comparing `slideflow-2.0.1.data/scripts/slideflow-studio.py` & `slideflow-2.0.2.data/scripts/slideflow-studio`

 * *Files 1% similar despite different names*

```diff
@@ -10,15 +10,15 @@
 
 from os.path import dirname, realpath, join
 from PIL import Image, ImageFont
 from contextlib import contextmanager
 from functools import lru_cache
 from os.path import join, dirname
 
-__version__ = "2.0.0"
+__version__ = "2.0.1"
 
 # -----------------------------------------------------------------------------
 
 @click.command()
 @click.argument('slide', metavar='PATH', required=False)
 @click.option('--model', '-m', help='Classifier network for categorical predictions.', metavar='PATH')
 @click.option('--project', '-p', help='Slideflow project.', metavar='PATH')
```

## Comparing `slideflow-2.0.1.dist-info/LICENSE` & `slideflow-2.0.2.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `slideflow-2.0.1.dist-info/METADATA` & `slideflow-2.0.2.dist-info/METADATA`

 * *Files 0% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: slideflow
-Version: 2.0.1
+Version: 2.0.2
 Summary: Deep learning tools for digital histology
 Home-page: https://github.com/jamesdolezal/slideflow
 Author: James Dolezal
 Author-email: james.dolezal@uchospitals.edu
 Classifier: Programming Language :: Python :: 3
 Classifier: License :: OSI Approved :: GNU General Public License v3 (GPLv3)
 Classifier: Operating System :: OS Independent
```

## Comparing `slideflow-2.0.1.dist-info/RECORD` & `slideflow-2.0.2.dist-info/RECORD`

 * *Files 2% similar despite different names*

```diff
@@ -1,11 +1,11 @@
 slideflow/__init__.py,sha256=Y463ep8Pwe89TUUVaqmFAbKmtQVjjDEEZHIlQ8unTE0,1411
 slideflow/_backend.py,sha256=Yi7LUgiYUUVlGdi6DBYe2raev3LLdYdtR6PtHozFORU,1662
-slideflow/_version.py,sha256=ZavQGjTygEdfjVnzZH8ZrXFwt_GLP6KP7q3xeTiG-GA,497
-slideflow/dataset.py,sha256=bXKwfFq4sLmIYxl7kESIkfW3Uzr2g4oSG4RiSnFjvB0,159660
+slideflow/_version.py,sha256=Uo5OTRpD2-qe8oCQcmtmUD-ytlU1XAN2XUEsbZmxwns,497
+slideflow/dataset.py,sha256=WH9YbMhBPI0qHL218Py96RvLV2m_fg9WrnNNsOpOjVQ,159745
 slideflow/errors.py,sha256=ueMKAc73Xz1OoSzibSt_qewJ29Lkk8KjkOkaNMw5ks0,3733
 slideflow/heatmap.py,sha256=7p6RenakRi01yo6DGH5mIUV9MfLQ66Q1iBPV6gnDV0Q,38304
 slideflow/mosaic.py,sha256=GjceACaGgxo2UKqa4AA0RSNaiGTMvEgW0ceFPUpjkrA,25615
 slideflow/project.py,sha256=do9n8psKyemUyWQ7nY1yl_ofI1JtZDB8kYrjIjga8YQ,168044
 slideflow/project_utils.py,sha256=YzjnuM3faru-lqQau7rBhuCyXGSGIXpSAmkR3hzCAio,33320
 slideflow/sample_actions.py,sha256=khhho6m0GzAXUD9licPFKlq8oxqY3hdP1qg1B3CTOMY,978
 slideflow/biscuit/__init__.py,sha256=iSjHWIB2GZloqeMxPhNSpb90gBagYm_hX7xut8rKf48,1195
@@ -158,16 +158,16 @@
 slideflow/io/io_utils.py,sha256=8oneye-50sEu9eZpaCzy2IdkrCGBd3WKlVSA4s8mW9A,9918
 slideflow/io/tensorflow.py,sha256=R52b44ZkKdUUoXHGDh02v28pV1fJ07EJ1LhmYKQQRi0,34511
 slideflow/io/torch.py,sha256=OXUtAVqEC45CXsXREMmD7EVl2aCAC90P9zVWpGtYXWI,44556
 slideflow/io/preservedsite/__init__.py,sha256=9chqMmsn_iKvFwnTxZtVr4Pn08dyOeEi4YpgKhrf1Kw,68
 slideflow/io/preservedsite/crossfolds.py,sha256=UD4e0JqgZJeYl9lfrFHkCKhePJHGbsB20ZK6CA3g7bU,8419
 slideflow/mil/__init__.py,sha256=H_nvcxN4HLMS_rnghdaBTqeaG6gb-7sJctm0UVz38Fc,284
 slideflow/mil/_params.py,sha256=sCpjitfJxCcsx7iTnOHqD2cLXJe0Z-qxzcldUTYWgBI,14819
-slideflow/mil/data.py,sha256=rtVJwoYz7Vo-EZpNJvLDNVbh0z13dult4EXEavt8cbU,5231
-slideflow/mil/eval.py,sha256=iA0iqKZc4wC7Z6YNt5qSwUkDSSylWEWyYkMCjhPwWcA,15323
+slideflow/mil/data.py,sha256=DIUUAPhAk0qthJQT6Oe4cfIxJmR5BXKPTbnXzH_sKoo,5160
+slideflow/mil/eval.py,sha256=QQkRaAMUGUZcPNPaajMV3sXNBZr4-6IMjqTlsRjbO8Q,15565
 slideflow/mil/clam/__init__.py,sha256=XFJYtb4FK5xQm7DqdmW3gBnG8IHYEjh3S1pzwFcbDKE,3890
 slideflow/mil/clam/create_attention.py,sha256=oGjZEfcT0zRqMhB8XITtFXHdw5Y9lNT9ZeiOcjntFtE,4334
 slideflow/mil/clam/datasets/__init__.py,sha256=lrqpfKa8fvcZHBzpmdJWt1uikjTNV8ZKqqpMIoRJkh4,1131
 slideflow/mil/clam/datasets/dataset_generic.py,sha256=Ulj-XQigidFsdx_DAoJ-RTQnY3jZucDtZH3YJ95Sw4g,14990
 slideflow/mil/clam/utils/__init__.py,sha256=EbG-maRA3elGYWTGMzVZbQfRqf2p9I8ojMHHJkb1MgU,5914
 slideflow/mil/clam/utils/core_utils.py,sha256=hWgMxfLv4gRWwyBzS0vhDRGJ4IF_AUz6IA6SedbII7U,19782
 slideflow/mil/clam/utils/eval_utils.py,sha256=zFFeNXOP-FhUg2HrYJxG_k5BUFwso1tJo_-kpIxAmWY,4150
@@ -181,18 +181,18 @@
 slideflow/mil/models/transmil.py,sha256=CpVxNifuytkGE7oRUcc2nFWJQHWo51xGXHtn8BIvk7A,4137
 slideflow/mil/train/__init__.py,sha256=SNILpMx3nYeBFYmO2Y_PoJAiC0LgdGKRAKD_pE052ec,15008
 slideflow/mil/train/_fastai.py,sha256=Af8wZL5gOaoKYq8helUE5SpfuxfcdZ8XxB24p4XXFTA,8214
 slideflow/mil/train/_legacy.py,sha256=v1s5Gqc46BZggwz7dcNyLuqVIM9lIYgUfNqTfH6d90A,7795
 slideflow/model/__init__.py,sha256=oJpmQVOsQiDUhI7RqD7WC3n5dKxkrOSA5Emkfgs-Vf0,7485
 slideflow/model/adv_utils.py,sha256=qt25QlPxEQk7vJtqc82DBlkw9KgSf8KkJvpC0ATzF7s,1879
 slideflow/model/base.py,sha256=0tOogk4fN9FMkrJCK5K0lgh3_vVI6KQIrfgMKBPQtg4,23588
-slideflow/model/features.py,sha256=xCVmqJMzEpgICPgooccA64N-T_WFAiaJIVoyqY6r3cE,55187
-slideflow/model/tensorflow.py,sha256=qfhD2GAYr_Dgcs59Cuy2RkdILAVE6-geRg3iUicX51E,110777
+slideflow/model/features.py,sha256=Y4f6GV3anOUNzsMVgBwRo2ct5ih-eRxs8oqIqgL54EI,55263
+slideflow/model/tensorflow.py,sha256=OY3JY_UK5ZIPdHGkjzQJfGE141LsWeQbaSWP7WMIYHg,110908
 slideflow/model/tensorflow_utils.py,sha256=5HYrVE8Ph3pSXjMfSRi7vmJIC_8mD3pQd28LLj1YAEY,22547
-slideflow/model/torch.py,sha256=rL7YpjxSja5-1QolWnDwJCFdtdFgOqvT5vT5goX-l88,103048
+slideflow/model/torch.py,sha256=TwJ0pgg_ZOyfT8EZXTBTjSfNoxrI4YhQxVnMrsIbidw,103179
 slideflow/model/torch_utils.py,sha256=Zudk3htcyZ1wnvZRX8z8xJsnwkS8M8n63vdqBQXaf54,16945
 slideflow/model/extractors/__init__.py,sha256=MEt448aADc_WUGzTSGF5IvW4Neu2atSiAFAyxzc-4uI,394
 slideflow/model/extractors/_factory.py,sha256=CXR4fa08GLM8Q4b_S5qIO1bmtzRX1VDtYrU7PjPFUHI,3708
 slideflow/model/extractors/_factory_tensorflow.py,sha256=zpvP7rOYQEvbuZbSlFY_L7iV0dub53kHS8fAcYNnaHs,4544
 slideflow/model/extractors/_factory_torch.py,sha256=-5kOiu91eBWq_9erNSTIj7DiUYg4edVKl5SPns0_9JQ,5711
 slideflow/model/extractors/_registry.py,sha256=BBudKPe2sOGvnNZFiuFJhjcKhHZdf2gRe0hheTN8ZKo,1570
 slideflow/model/extractors/_slide.py,sha256=nC0OzgF8_11f5ql0oujeVymM8X8DJ6HU71C4ts-Q9s8,2646
@@ -214,24 +214,24 @@
 slideflow/norm/torch/color.py,sha256=dN1FpcvdVLvmkjGdc77rA4r0q0Clhhr_sQR2fEh18Vc,7826
 slideflow/norm/torch/macenko.py,sha256=BpVulIdIXUhaUrJnFgHBF1W4jj2ZVTXB4lDiSSkxtEo,14869
 slideflow/norm/torch/reinhard.py,sha256=xE74ZJQTDJckRgumwNikRy3UT8KDq1EoumHO3x3BaVc,24997
 slideflow/norm/torch/utils.py,sha256=MstCD6KIJGG2a7xHAfSpLVr95jcoKrXrW2xDxch79pQ,1673
 slideflow/simclr/__init__.py,sha256=o8TiOkbZzvsQo6bISoejBrOscbq_l-akGzbGr92rkK4,458
 slideflow/simclr/simclr/__init__.py,sha256=M1HPoNrZnhd3zOIQyYO1YXGBeA22ZXmi6BeSccg5774,6
 slideflow/simclr/simclr/tf2/__init__.py,sha256=H_209JGDuRkTGk0kJe1kRgUTg26KyU1AfoEQXpUhV3Q,20637
-slideflow/simclr/simclr/tf2/data.py,sha256=naonmzXXd1sPYmTkbFiGrJVpJWXgenwIz8_l7T7gsM8,10131
+slideflow/simclr/simclr/tf2/data.py,sha256=wKVweVOUpusJfo9lkGpN5lo_xiDOr-lUfjBtZIlymzA,10701
 slideflow/simclr/simclr/tf2/data_util.py,sha256=wu0vlo_H_yL8aFCWWGpknf1Z3Apu3gsiyaiEGaEPcRY,18550
-slideflow/simclr/simclr/tf2/lars_optimizer.py,sha256=yJVRWbEDJsiVCzZnP-6_fS9VA7v36txA3DAEbVds59U,6315
+slideflow/simclr/simclr/tf2/lars_optimizer.py,sha256=XWLnxqVxRlUY6PsQOHiCsFB6Lluk3TOokasLH9TTO-o,6505
 slideflow/simclr/simclr/tf2/metrics.py,sha256=RUtmvVamcnS-8_ZXLE2XdALsLgNgVPOUNl17hKPk13Y,2997
 slideflow/simclr/simclr/tf2/model.py,sha256=3p7YnZeZS09XOkPbVJ19dl77h7w3DNuf4c6rd6gqlqA,12256
 slideflow/simclr/simclr/tf2/objective.py,sha256=v5V1UzGCaSzT1i6xDe4UOaUIOhQyZ9sPDlrEP_2XYQ8,4983
 slideflow/simclr/simclr/tf2/resnet.py,sha256=BJgzhGO3TudNubzAAsx3jl8wsUW6DJ8EzivN3qlV9wY,28397
 slideflow/simclr/simclr/tf2/run.py,sha256=8Ej3YtqrKgpqlh0sjyqbUmKvLPGIRLz7XYi44dpvPE0,6524
 slideflow/simclr/simclr/tf2/utils.py,sha256=BEiKTWmuJ0XbZfG15413xPs_KnNmRg5uYL0QZEzgDYo,9517
-slideflow/slide/__init__.py,sha256=r2ip2MuMLjfjwOMmSTY2bKQ-wLkX6aY5VgXYEyKArqs,111594
+slideflow/slide/__init__.py,sha256=ir6UIq09q638pVRZZYqAEmR3JWWYdBmI8MM0ylMWy1Y,114638
 slideflow/slide/report.py,sha256=A0GEqPN5MisFk9gWuAsFq0qRBuUd1NccZgnHM7UyNHU,19045
 slideflow/slide/slideflow-logo-name-small.jpg,sha256=C9-2QV_cZkmn_FqzvorF5GvrkD__VE-7NSKME58fTR8,30934
 slideflow/slide/utils.py,sha256=5NmVU1LdFdBciwJLg_Sh9xMU4DgXEVKEB-XV7jBf2lc,5516
 slideflow/slide/backends/__init__.py,sha256=9BjTu2AaVW8zySEvLrZ-RQ21ET9kqSajYV8YkCMpAzU,708
 slideflow/slide/backends/cucim.py,sha256=dcQzgy8BzktiOY2v8t_EJn35X7OG4orC1RMWPv-qRZ4,14008
 slideflow/slide/backends/vips.py,sha256=VbBwd4S8q2-YyXl_56Nb12E8XW5-u8gWu43jXo6YN9A,22391
 slideflow/slide/qc/__init__.py,sha256=ePMfd6ZlrWdxYiRkS6gsCIMoGfS3hDPuqIyjX7kQT30,117
@@ -311,26 +311,26 @@
 slideflow/studio/gui/viewer/_mosaic.py,sha256=dKDyGt12-f9sju5g0plSJUoOiP4uYAH2emiK3vQFUb0,7874
 slideflow/studio/gui/viewer/_slide.py,sha256=64C67XjagXAQMul4XLN237q2EWGElP4Nt_kjM2dwBGg,24818
 slideflow/studio/gui/viewer/_viewer.py,sha256=M_aVUL7tZRyOI2OhI3xiRUVpQe3kunoLAt5kfRMxZSM,14452
 slideflow/studio/widgets/__init__.py,sha256=M8gSPhj8W4FThgSm5kMF1GuAffF1PkauBfU5xtwAmxI,439
 slideflow/studio/widgets/_utils.py,sha256=jI9Ah-aO4SPN8CdBB0pWV2-bxifLSW6DpGK106938js,735
 slideflow/studio/widgets/capture.py,sha256=MtXvouNKrMcxfmHVN4xBv1ODK-clnC3-QzH8waowHmc,4264
 slideflow/studio/widgets/extensions.py,sha256=V7u_T1t5IxiqRfiza9ru5UgvPBUruvLI7dXmTBwlnm8,5412
-slideflow/studio/widgets/heatmap.py,sha256=SWkACMxN5Strm3DwOLvEe14thVwQFa9D5cOAGJNYGKc,17013
+slideflow/studio/widgets/heatmap.py,sha256=P_7Bpz3T9MxxFBCeA9moD0TcLRkrbJvV_1QlRVbRriY,16890
 slideflow/studio/widgets/layer_umap.py,sha256=Dol3NIxJge6Ff2e80Ydjvfh0xc8CBMb34DmM-n1lPmg,3842
 slideflow/studio/widgets/model.py,sha256=T50CTM8jt1e_lNrmh4zx7XOQdTh9S6RApmnJp1Gh7fw,24474
 slideflow/studio/widgets/mosaic.py,sha256=u1a_HvZ20PWuzdQ1EVAWIP9HOUE85m42OvLDY0i4pKk,14307
 slideflow/studio/widgets/mosaic_experimental.py,sha256=_Z3huwfE3uJeP3-Fs_PwAvJ00T8ekykeWBvTH2AXN4k,2597
 slideflow/studio/widgets/performance.py,sha256=kTk3fuS6M5mQ5K4pmKZvx5sVJC070IHImfPTCQbxNec,4662
 slideflow/studio/widgets/picam.py,sha256=K_z4pt1-VvU0HkWfyO0NsOEqne4utfr8blZjpxoIvRI,6437
 slideflow/studio/widgets/project.py,sha256=naeSkPx8X_euzt2DBU0LLcI7Lod_824ygcf5m6QPrpQ,7726
 slideflow/studio/widgets/seed_map.py,sha256=b4ftLvj5ySevm9zKjhcKN-HOQSYlza1JKEhknw83aa4,5983
 slideflow/studio/widgets/segment.py,sha256=ocfTzY3fansXaQoPGFUxvVBg2nbzbH8KzRtUpzjQ9-E,19875
 slideflow/studio/widgets/settings.py,sha256=L6etk5UsWrzLxa_5c7S70ABTllviiFAKPZFLw4fFE7o,2071
-slideflow/studio/widgets/slide.py,sha256=rPsEjfW3aKpGOHMmkpjqUnOQO-d7ufmoiJ3n5tEDutY,31074
+slideflow/studio/widgets/slide.py,sha256=B5o-96jdTKFVCeD5DxqKrLd8DQrby9-0YjTXvxGOf4U,31018
 slideflow/studio/widgets/stylegan.py,sha256=wV9mYOpEr11jRQd2e-yNHrbyShyjGaUsIKAvNmvjY4k,16402
 slideflow/test/__init__.py,sha256=5IsYXrynGmJDMLmjueGyMzBVbifbmEBAzSEGf_HRhw4,32309
 slideflow/test/dataset_test.py,sha256=XJOx1T-J5Rcsjwx54kLY6-GuOQEgUtO_-a6sW9oXVvE,12446
 slideflow/test/functional.py,sha256=V6vs6N-ty49oan2KbM80nT4EmMis9-mQ3UZbVuH-woI,9560
 slideflow/test/model_test.py,sha256=rLiz27NDLOukTbTEPUL88a-aPeSe2ePgScatV4VM7_s,8052
 slideflow/test/norm_test.py,sha256=au7oXuHg-LzfX84nJw6-mSEKa4R46JL4eu9j7hW_r4U,12098
 slideflow/test/slide_test.py,sha256=P-cmg5JpL2LgpyrP61lF5YMpZ9vqmR6sSuJjNGFhIso,2909
@@ -345,15 +345,15 @@
 slideflow/tfrecord/torch/dataset.py,sha256=Vc9q1vHG0xTtMu-tsi-kX1c9wM95BNWb9r5CWzh8B0w,7857
 slideflow/util/__init__.py,sha256=xaoOXySQBk5xPlk7arNDV1ZAp4ohvvh0dsBw6KNLiOg,41104
 slideflow/util/colors.py,sha256=KOfggJhBNe3uHYa4MNQYdJnOb3A-Nyl1lxIMQ6Sqivc,738
 slideflow/util/example_pb2.py,sha256=oU4oQBXz89HAyrehrDeK-uJYqL7eNznjd8y3YDwn0dY,17912
 slideflow/util/log_utils.py,sha256=kyfTOCmSJW7gIW_1nHXiyPydN-jyO8YEBM3wiEb5OUc,4468
 slideflow/util/neptune_utils.py,sha256=rus5wDerStaFQalTbF9VaEbi6OelhkpkUHmwt0ggejQ,4381
 slideflow/util/smac_utils.py,sha256=T_-b1Wv0V2fQVX-FGlnhX1i4bu69imixlbAJd2aNJgs,20061
-slideflow/util/tfrecord2idx.py,sha256=k3QHnE5T1o_qPHT-mRKBomfyPha9Ud_zsS-zKA_EKlY,7920
-slideflow-2.0.1.data/scripts/slideflow-studio,sha256=dYg_ktDH_I74oIs8Sj4l56M-03frzO4KisE7WeXAofI,14085
-slideflow-2.0.1.data/scripts/slideflow-studio.py,sha256=dYg_ktDH_I74oIs8Sj4l56M-03frzO4KisE7WeXAofI,14085
-slideflow-2.0.1.dist-info/LICENSE,sha256=OXLcl0T2SZ8Pmy2_dmlvKuetivmyPd5m1q-Gyd-zaYY,35149
-slideflow-2.0.1.dist-info/METADATA,sha256=icziIiXMBAeCIuv_kO0y6-7km7X9eXlMbY1x4G6X9zs,12998
-slideflow-2.0.1.dist-info/WHEEL,sha256=G16H4A3IeoQmnOrYV4ueZGKSjhipXx8zc8nu9FGlvMA,92
-slideflow-2.0.1.dist-info/top_level.txt,sha256=FRikcoh3_TcsLUYbI4LowF3nrEDWcGLaAyNgsi9Lu9M,10
-slideflow-2.0.1.dist-info/RECORD,,
+slideflow/util/tfrecord2idx.py,sha256=RADRWAR2J4YJITIsaIHoNxsGJXbTkKQqs9xtW2kxXJ0,8046
+slideflow-2.0.2.data/scripts/slideflow-studio,sha256=BljDc6Eig-Hl5HLA41v-5VENDbTTkmHtK-mUAGHM1Ro,14085
+slideflow-2.0.2.data/scripts/slideflow-studio.py,sha256=dYg_ktDH_I74oIs8Sj4l56M-03frzO4KisE7WeXAofI,14085
+slideflow-2.0.2.dist-info/LICENSE,sha256=OXLcl0T2SZ8Pmy2_dmlvKuetivmyPd5m1q-Gyd-zaYY,35149
+slideflow-2.0.2.dist-info/METADATA,sha256=KjNONXdXLOSqTqlDhuK_ji57oPjMa2PgHldt5cHWxwQ,12998
+slideflow-2.0.2.dist-info/WHEEL,sha256=G16H4A3IeoQmnOrYV4ueZGKSjhipXx8zc8nu9FGlvMA,92
+slideflow-2.0.2.dist-info/top_level.txt,sha256=FRikcoh3_TcsLUYbI4LowF3nrEDWcGLaAyNgsi9Lu9M,10
+slideflow-2.0.2.dist-info/RECORD,,
```

