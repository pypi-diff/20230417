# Comparing `tmp/bigdl_nano-2.3.0b20230416-py3-none-win_amd64.whl.zip` & `tmp/bigdl_nano-2.3.0b20230417-py3-none-win_amd64.whl.zip`

## zipinfo {}

```diff
@@ -1,8 +1,8 @@
-Zip file size: 2987100 bytes, number of entries: 224
+Zip file size: 2989081 bytes, number of entries: 224
 -rw-------  2.0 unx      956 b- defN 23-Apr-17 02:22 bigdl/__init__.py
 -rw-------  2.0 unx     1554 b- defN 23-Apr-17 02:22 bigdl/nano/__init__.py
 -rw-------  2.0 unx      684 b- defN 23-Apr-17 02:22 bigdl/nano/openvino.py
 -rw-------  2.0 unx      734 b- defN 23-Apr-17 02:22 bigdl/nano/automl/__init__.py
 -rw-------  2.0 unx      633 b- defN 23-Apr-17 02:22 bigdl/nano/automl/hpo/__init__.py
 -rw-------  2.0 unx     1888 b- defN 23-Apr-17 02:22 bigdl/nano/automl/hpo/backend.py
 -rw-------  2.0 unx     8486 b- defN 23-Apr-17 02:22 bigdl/nano/automl/hpo/callgraph.py
@@ -74,39 +74,39 @@
 -rw-------  2.0 unx      586 b- defN 23-Apr-17 02:22 bigdl/nano/deps/onnxruntime/pytorch/__init__.py
 -rw-------  2.0 unx     7854 b- defN 23-Apr-17 02:22 bigdl/nano/deps/onnxruntime/pytorch/pytorch_onnxruntime_model.py
 -rw-------  2.0 unx      586 b- defN 23-Apr-17 02:22 bigdl/nano/deps/onnxruntime/tensorflow/__init__.py
 -rw-------  2.0 unx     7852 b- defN 23-Apr-17 02:22 bigdl/nano/deps/onnxruntime/tensorflow/model.py
 -rw-------  2.0 unx      586 b- defN 23-Apr-17 02:22 bigdl/nano/deps/onnxsim/__init__.py
 -rw-------  2.0 unx     1105 b- defN 23-Apr-17 02:22 bigdl/nano/deps/onnxsim/onnxsim_api.py
 -rw-------  2.0 unx      586 b- defN 23-Apr-17 02:22 bigdl/nano/deps/openvino/__init__.py
--rw-------  2.0 unx     6365 b- defN 23-Apr-17 02:22 bigdl/nano/deps/openvino/openvino_api.py
+-rw-------  2.0 unx     6986 b- defN 23-Apr-17 08:03 bigdl/nano/deps/openvino/openvino_api.py
 -rw-------  2.0 unx      872 b- defN 23-Apr-17 02:22 bigdl/nano/deps/openvino/core/__init__.py
 -rw-------  2.0 unx     2129 b- defN 23-Apr-17 02:22 bigdl/nano/deps/openvino/core/metric.py
--rw-------  2.0 unx    10572 b- defN 23-Apr-17 02:22 bigdl/nano/deps/openvino/core/model.py
+-rw-------  2.0 unx    14225 b- defN 23-Apr-17 08:03 bigdl/nano/deps/openvino/core/model.py
 -rw-------  2.0 unx     4075 b- defN 23-Apr-17 02:22 bigdl/nano/deps/openvino/core/utils.py
 -rw-------  2.0 unx      586 b- defN 23-Apr-17 02:22 bigdl/nano/deps/openvino/pytorch/__init__.py
 -rw-------  2.0 unx     1519 b- defN 23-Apr-17 02:22 bigdl/nano/deps/openvino/pytorch/dataloader.py
 -rw-------  2.0 unx     1668 b- defN 23-Apr-17 02:22 bigdl/nano/deps/openvino/pytorch/metric.py
--rw-------  2.0 unx    12317 b- defN 23-Apr-17 02:22 bigdl/nano/deps/openvino/pytorch/model.py
+-rw-------  2.0 unx    13001 b- defN 23-Apr-17 08:03 bigdl/nano/deps/openvino/pytorch/model.py
 -rw-------  2.0 unx     2616 b- defN 23-Apr-17 02:22 bigdl/nano/deps/openvino/pytorch/utils.py
 -rw-------  2.0 unx      586 b- defN 23-Apr-17 02:22 bigdl/nano/deps/openvino/tf/__init__.py
 -rw-------  2.0 unx     1845 b- defN 23-Apr-17 02:22 bigdl/nano/deps/openvino/tf/dataloader.py
 -rw-------  2.0 unx     1499 b- defN 23-Apr-17 02:22 bigdl/nano/deps/openvino/tf/metric.py
--rw-------  2.0 unx     9735 b- defN 23-Apr-17 02:22 bigdl/nano/deps/openvino/tf/model.py
+-rw-------  2.0 unx    10317 b- defN 23-Apr-17 08:03 bigdl/nano/deps/openvino/tf/model.py
 -rw-------  2.0 unx     1676 b- defN 23-Apr-17 02:22 bigdl/nano/deps/openvino/tf/utils.py
 -rw-------  2.0 unx      586 b- defN 23-Apr-17 02:22 bigdl/nano/deps/ray/__init__.py
 -rw-------  2.0 unx     1265 b- defN 23-Apr-17 02:22 bigdl/nano/deps/ray/ray_api.py
 -rw-------  2.0 unx     1530 b- defN 23-Apr-17 02:22 bigdl/nano/deps/ray/ray_backend.py
 -rw-------  2.0 unx    18650 b- defN 23-Apr-17 02:22 bigdl/nano/deps/ray/ray_distributed.py
 -rw-------  2.0 unx     3705 b- defN 23-Apr-17 02:22 bigdl/nano/deps/ray/ray_envbase.py
 -rw-------  2.0 unx      618 b- defN 23-Apr-17 02:22 bigdl/nano/k8s/__init__.py
 -rw-------  2.0 unx    13183 b- defN 23-Apr-17 02:22 bigdl/nano/k8s/bigdl_submit.py
--rwx------  2.0 unx  5460184 b- defN 23-Apr-17 04:18 bigdl/nano/libs/libjemalloc.so
--rwx------  2.0 unx  1432624 b- defN 23-Apr-17 04:18 bigdl/nano/libs/libtcmalloc.so
--rwx------  2.0 unx   918296 b- defN 23-Apr-17 04:18 bigdl/nano/libs/libturbojpeg.so.0.2.0
+-rwx------  2.0 unx  5460184 b- defN 23-Apr-17 14:19 bigdl/nano/libs/libjemalloc.so
+-rwx------  2.0 unx  1432624 b- defN 23-Apr-17 14:19 bigdl/nano/libs/libtcmalloc.so
+-rwx------  2.0 unx   918296 b- defN 23-Apr-17 14:19 bigdl/nano/libs/libturbojpeg.so.0.2.0
 -rw-------  2.0 unx     2113 b- defN 23-Apr-17 02:22 bigdl/nano/pytorch/__init__.py
 -rw-------  2.0 unx     5657 b- defN 23-Apr-17 02:22 bigdl/nano/pytorch/context_manager.py
 -rw-------  2.0 unx     3245 b- defN 23-Apr-17 02:22 bigdl/nano/pytorch/dispatcher.py
 -rw-------  2.0 unx     5818 b- defN 23-Apr-17 02:22 bigdl/nano/pytorch/lightning.py
 -rw-------  2.0 unx     3063 b- defN 23-Apr-17 02:22 bigdl/nano/pytorch/model.py
 -rw-------  2.0 unx    18937 b- defN 23-Apr-17 02:22 bigdl/nano/pytorch/torch_nano.py
 -rw-------  2.0 unx      706 b- defN 23-Apr-17 02:22 bigdl/nano/pytorch/algorithms/__init__.py
@@ -115,15 +115,15 @@
 -rw-------  2.0 unx      609 b- defN 23-Apr-17 02:22 bigdl/nano/pytorch/amp/__init__.py
 -rw-------  2.0 unx      805 b- defN 23-Apr-17 02:22 bigdl/nano/pytorch/amp/amp_api.py
 -rw-------  2.0 unx     9569 b- defN 23-Apr-17 02:22 bigdl/nano/pytorch/amp/bfloat16.py
 -rw-------  2.0 unx      640 b- defN 23-Apr-17 02:22 bigdl/nano/pytorch/encryption/__init__.py
 -rw-------  2.0 unx     6480 b- defN 23-Apr-17 02:22 bigdl/nano/pytorch/encryption/encryption.py
 -rw-------  2.0 unx      661 b- defN 23-Apr-17 02:22 bigdl/nano/pytorch/inference/__init__.py
 -rw-------  2.0 unx     4231 b- defN 23-Apr-17 02:22 bigdl/nano/pytorch/inference/multi_instance.py
--rw-------  2.0 unx    86189 b- defN 23-Apr-17 02:22 bigdl/nano/pytorch/inference/optimizer.py
+-rw-------  2.0 unx    86860 b- defN 23-Apr-17 08:03 bigdl/nano/pytorch/inference/optimizer.py
 -rw-------  2.0 unx     4593 b- defN 23-Apr-17 02:22 bigdl/nano/pytorch/inference/pipeline.py
 -rw-------  2.0 unx     3015 b- defN 23-Apr-17 02:22 bigdl/nano/pytorch/low_precision/jit_int8_api.py
 -rw-------  2.0 unx     9651 b- defN 23-Apr-17 02:22 bigdl/nano/pytorch/low_precision/jit_int8_model.py
 -rw-------  2.0 unx      646 b- defN 23-Apr-17 02:22 bigdl/nano/pytorch/optim/__init__.py
 -rw-------  2.0 unx     8351 b- defN 23-Apr-17 02:22 bigdl/nano/pytorch/optim/sparseadam.py
 -rw-------  2.0 unx      804 b- defN 23-Apr-17 02:22 bigdl/nano/pytorch/patching/__init__.py
 -rw-------  2.0 unx      627 b- defN 23-Apr-17 02:22 bigdl/nano/pytorch/patching/dtype_patching/__init__.py
@@ -197,30 +197,30 @@
 -rw-------  2.0 unx     4527 b- defN 23-Apr-17 02:22 bigdl/nano/utils/pytorch/channel_last.py
 -rw-------  2.0 unx     1807 b- defN 23-Apr-17 02:22 bigdl/nano/utils/pytorch/check_deps.py
 -rw-------  2.0 unx     3358 b- defN 23-Apr-17 02:22 bigdl/nano/utils/pytorch/convert.py
 -rw-------  2.0 unx     6234 b- defN 23-Apr-17 02:22 bigdl/nano/utils/pytorch/dataloader.py
 -rw-------  2.0 unx     1321 b- defN 23-Apr-17 02:22 bigdl/nano/utils/pytorch/dataset.py
 -rw-------  2.0 unx     3881 b- defN 23-Apr-17 02:22 bigdl/nano/utils/pytorch/input_sample.py
 -rw-------  2.0 unx     4952 b- defN 23-Apr-17 02:22 bigdl/nano/utils/pytorch/inspect.py
--rw-------  2.0 unx     5714 b- defN 23-Apr-17 02:22 bigdl/nano/utils/pytorch/load.py
+-rw-------  2.0 unx     6270 b- defN 23-Apr-17 08:03 bigdl/nano/utils/pytorch/load.py
 -rw-------  2.0 unx     1391 b- defN 23-Apr-17 02:22 bigdl/nano/utils/pytorch/metric.py
 -rw-------  2.0 unx     5531 b- defN 23-Apr-17 02:22 bigdl/nano/utils/pytorch/model_info.py
 -rw-------  2.0 unx     2878 b- defN 23-Apr-17 02:22 bigdl/nano/utils/pytorch/save.py
 -rw-------  2.0 unx     1189 b- defN 23-Apr-17 02:22 bigdl/nano/utils/pytorch/version.py
 -rw-------  2.0 unx     1012 b- defN 23-Apr-17 02:22 bigdl/nano/utils/pytorch/xpu.py
 -rw-------  2.0 unx     1057 b- defN 23-Apr-17 02:22 bigdl/nano/utils/tf/__init__.py
 -rw-------  2.0 unx     4300 b- defN 23-Apr-17 02:22 bigdl/nano/utils/tf/attributes.py
 -rw-------  2.0 unx     2816 b- defN 23-Apr-17 02:22 bigdl/nano/utils/tf/backend.py
 -rw-------  2.0 unx     7421 b- defN 23-Apr-17 02:22 bigdl/nano/utils/tf/data.py
 -rw-------  2.0 unx     2582 b- defN 23-Apr-17 02:22 bigdl/nano/utils/tf/preprocess.py
 -rw-------  2.0 unx     1347 b- defN 23-Apr-17 02:22 bigdl/nano/utils/tf/subprocess_worker.py
 -rw-------  2.0 unx      823 b- defN 23-Apr-17 02:22 bigdl/nano/utils/tf/version.py
--rwxr-xr-x  2.0 unx    12068 b- defN 23-Apr-17 02:22 bigdl_nano-2.3.0b20230416.data/scripts/bigdl-nano-init
--rwxr-xr-x  2.0 unx      909 b- defN 23-Apr-17 02:22 bigdl_nano-2.3.0b20230416.data/scripts/bigdl-nano-init.ps1
--rwxr-xr-x  2.0 unx      214 b- defN 23-Apr-17 02:22 bigdl_nano-2.3.0b20230416.data/scripts/bigdl-nano-unset-env
--rwxr-xr-x  2.0 unx      127 b- defN 23-Apr-17 02:22 bigdl_nano-2.3.0b20230416.data/scripts/bigdl-nano-unset-env.ps1
--rw-------  2.0 unx    10112 b- defN 23-Apr-17 04:18 bigdl_nano-2.3.0b20230416.dist-info/METADATA
--rw-------  2.0 unx       98 b- defN 23-Apr-17 04:18 bigdl_nano-2.3.0b20230416.dist-info/WHEEL
--rw-------  2.0 unx       54 b- defN 23-Apr-17 04:18 bigdl_nano-2.3.0b20230416.dist-info/entry_points.txt
--rw-------  2.0 unx        6 b- defN 23-Apr-17 04:18 bigdl_nano-2.3.0b20230416.dist-info/top_level.txt
--rw-rw-r--  2.0 unx    21776 b- defN 23-Apr-17 04:18 bigdl_nano-2.3.0b20230416.dist-info/RECORD
-224 files, 8810011 bytes uncompressed, 2951854 bytes compressed:  66.5%
+-rwxr-xr-x  2.0 unx    12068 b- defN 23-Apr-17 02:22 bigdl_nano-2.3.0b20230417.data/scripts/bigdl-nano-init
+-rwxr-xr-x  2.0 unx      909 b- defN 23-Apr-17 02:22 bigdl_nano-2.3.0b20230417.data/scripts/bigdl-nano-init.ps1
+-rwxr-xr-x  2.0 unx      214 b- defN 23-Apr-17 02:22 bigdl_nano-2.3.0b20230417.data/scripts/bigdl-nano-unset-env
+-rwxr-xr-x  2.0 unx      127 b- defN 23-Apr-17 02:22 bigdl_nano-2.3.0b20230417.data/scripts/bigdl-nano-unset-env.ps1
+-rw-------  2.0 unx    10112 b- defN 23-Apr-17 14:19 bigdl_nano-2.3.0b20230417.dist-info/METADATA
+-rw-------  2.0 unx       98 b- defN 23-Apr-17 14:19 bigdl_nano-2.3.0b20230417.dist-info/WHEEL
+-rw-------  2.0 unx       54 b- defN 23-Apr-17 14:19 bigdl_nano-2.3.0b20230417.dist-info/entry_points.txt
+-rw-------  2.0 unx        6 b- defN 23-Apr-17 14:19 bigdl_nano-2.3.0b20230417.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx    21777 b- defN 23-Apr-17 14:19 bigdl_nano-2.3.0b20230417.dist-info/RECORD
+224 files, 8816779 bytes uncompressed, 2953835 bytes compressed:  66.5%
```

## zipnote {}

```diff
@@ -639,35 +639,35 @@
 
 Filename: bigdl/nano/utils/tf/subprocess_worker.py
 Comment: 
 
 Filename: bigdl/nano/utils/tf/version.py
 Comment: 
 
-Filename: bigdl_nano-2.3.0b20230416.data/scripts/bigdl-nano-init
+Filename: bigdl_nano-2.3.0b20230417.data/scripts/bigdl-nano-init
 Comment: 
 
-Filename: bigdl_nano-2.3.0b20230416.data/scripts/bigdl-nano-init.ps1
+Filename: bigdl_nano-2.3.0b20230417.data/scripts/bigdl-nano-init.ps1
 Comment: 
 
-Filename: bigdl_nano-2.3.0b20230416.data/scripts/bigdl-nano-unset-env
+Filename: bigdl_nano-2.3.0b20230417.data/scripts/bigdl-nano-unset-env
 Comment: 
 
-Filename: bigdl_nano-2.3.0b20230416.data/scripts/bigdl-nano-unset-env.ps1
+Filename: bigdl_nano-2.3.0b20230417.data/scripts/bigdl-nano-unset-env.ps1
 Comment: 
 
-Filename: bigdl_nano-2.3.0b20230416.dist-info/METADATA
+Filename: bigdl_nano-2.3.0b20230417.dist-info/METADATA
 Comment: 
 
-Filename: bigdl_nano-2.3.0b20230416.dist-info/WHEEL
+Filename: bigdl_nano-2.3.0b20230417.dist-info/WHEEL
 Comment: 
 
-Filename: bigdl_nano-2.3.0b20230416.dist-info/entry_points.txt
+Filename: bigdl_nano-2.3.0b20230417.dist-info/entry_points.txt
 Comment: 
 
-Filename: bigdl_nano-2.3.0b20230416.dist-info/top_level.txt
+Filename: bigdl_nano-2.3.0b20230417.dist-info/top_level.txt
 Comment: 
 
-Filename: bigdl_nano-2.3.0b20230416.dist-info/RECORD
+Filename: bigdl_nano-2.3.0b20230417.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## bigdl/nano/deps/openvino/openvino_api.py

```diff
@@ -63,29 +63,38 @@
                                 dynamic_axes=dynamic_axes,
                                 logging=logging,
                                 config=config,
                                 output_tensors=output_tensors,
                                 **kwargs)
 
 
-def load_openvino_model(path, framework='pytorch', device=None):
+def load_openvino_model(path, framework='pytorch', device=None, cache_dir=None, shapes=None):
     """
     Load an OpenVINO model for inference from directory.
 
     :param path: Path to model to be loaded.
     :param framework: Only support pytorch and tensorflow now
     :param device: A string represents the device of the inference.
+    :param cache_dir: A directory for OpenVINO to cache the model. Default to None.
+    :param shapes: input shape. For example, 'input1[1,3,224,224],input2[1,4]',
+               '[1,3,224,224]'. This parameter affect model Parameter shape, can be
+               dynamic. For dynamic dimesions use symbol `?`, `-1` or range `low.. up`.'.
+               Only valid for openvino model, otherwise will be ignored.
     :return: PytorchOpenVINOModel model for OpenVINO inference.
     """
+    if cache_dir is not None:
+        from pathlib import Path
+        Path(cache_dir).mkdir(exist_ok=True)
+
     if framework == 'pytorch':
         from .pytorch.model import PytorchOpenVINOModel
-        return PytorchOpenVINOModel._load(path, device=device)
+        return PytorchOpenVINOModel._load(path, device=device, cache_dir=cache_dir, shapes=shapes)
     elif framework == 'tensorflow':
         from .tf.model import KerasOpenVINOModel
-        return KerasOpenVINOModel._load(path, device=device)
+        return KerasOpenVINOModel._load(path, device=device, cache_dir=cache_dir, shapes=shapes)
     else:
         invalidInputError(False,
                           "The value {} for framework is not supported."
                           " Please choose from 'pytorch'/'tensorflow'.")
 
 
 def KerasOpenVINOModel(model, input_spec=None, precision='fp32',
```

## bigdl/nano/deps/openvino/core/model.py

```diff
@@ -17,27 +17,29 @@
 from tempfile import TemporaryDirectory
 from typing import List, Union  # for typehint
 from openvino.runtime import Core
 from bigdl.nano.utils.common import invalidInputError, _flatten
 from openvino.runtime import Model
 from openvino.runtime import AsyncInferQueue
 import numpy as np
+from datetime import datetime
 from .utils import save, OpenVINO_LESS_2022_3
 
 
 class OpenVINOModel:
     def __init__(self, ie_network: str, device='CPU', precision='fp32',
-                 thread_num=None, config=None):
+                 thread_num=None, config=None, shapes=None):
         self._ie = Core()
         # check device
         self._check_device(self._ie, device)
         self._device = device
         self._precision = precision
         self.thread_num = thread_num
         self.additional_config = config
+        self.shapes = shapes
         self.ie_network = ie_network
 
     def on_forward_start(self, inputs):
         self._model_exists_or_err()
         return inputs
 
     def forward_step(self, *inputs, **kwargs):
@@ -106,25 +108,107 @@
         if self.thread_num is not None and self._device == 'CPU':
             if OpenVINO_LESS_2022_3:
                 config = {"CPU_THREADS_NUM": str(self.thread_num)}
             else:
                 config = {"INFERENCE_NUM_THREADS": str(self.thread_num)}
         else:
             config = {}
-        if self.additional_config is not None and self._device == 'CPU':
-            # TODO: check addition config based on device
-            config.update(self.additional_config)
-        self._compiled_model = self._ie.compile_model(model=self.ie_network,
-                                                      device_name=self._device,
-                                                      config=config)
-        self._infer_request = self._compiled_model.create_infer_request()
+        if self.additional_config is not None:
+            if self._device == 'CPU':
+                # TODO: check addition config based on device
+                config.update(self.additional_config)
+            else:
+                ov_cache_dir = self.additional_config.get("CACHE_DIR", None)
+                if ov_cache_dir:
+                    config["CACHE_DIR"] = ov_cache_dir
         self.final_config = config
+
+        if self.shapes is None:
+            self.create_infer_request()
+        else:
+            self._infer_request = None
+            self.reshape(self.shapes)
+
         input_names = [t.any_name for t in self._ie_network.inputs]
         self._forward_args = input_names
 
+    def create_infer_request(self):
+        start_time = datetime.utcnow()
+        self._compiled_model = self._ie.compile_model(model=self.ie_network,
+                                                      device_name=self._device,
+                                                      config=self.final_config)
+        self._infer_request = self._compiled_model.create_infer_request()
+        duration_ms = f"{(datetime.utcnow() - start_time).total_seconds() * 1000:.2f}"
+        print(f"Compile model and create infer request took {duration_ms} ms")
+
+    def reshape(self, shapes):
+        """
+        Reshape the model to fit the inputs.Be aware that not all models support reshaping,
+        and models that do, may not support all input shapes. The model accuracy may also
+        suffer if you reshape the model.
+        :param shapes: input shape. For example, 'input1[1,3,224,224],input2[1,4]', '[1,3,224,224]'.
+               This parameter affect model Parameter shape, can be dynamic. For dynamic dimesions
+               use symbol `?`, `-1` or range `low.. up`.'
+        """
+        invalidInputError(isinstance(shapes, str), "Shapes only supports string inputs "
+                          "like 'input1[1,3,224,224],input2[1,4]', '[1,3,224,224]' but got "
+                          f"{shapes.__class__.__name__}.")
+
+        shapes, reshape = self._get_reshape_info(shapes)
+        if not reshape:
+            print("Skip the reshape process since the input shapes are same as the current "
+                  "model shapes.")
+            if self._infer_request:
+                print("Skip compiling model.")
+                return
+        else:
+            start_time = datetime.utcnow()
+            print('Reshaping model: {}'
+                  .format(', '.join("'{}': {}".format(k, str(v)) for k, v in shapes.items())))
+            try:
+                self.ie_network.reshape(shapes)
+                duration_ms = f"{(datetime.utcnow() - start_time).total_seconds() * 1000:.2f}"
+                print(f"Reshape model took {duration_ms} ms")
+            except Exception as e:
+                print(f"Failed to reshape this model. Error message: {str(e)}")
+                if self._infer_request:
+                    return
+                else:
+                    print("Compile the original model instead.")
+
+        self.create_infer_request()
+
+    def _get_reshape_info(self, shapes):
+        invalidInputError(isinstance(shapes, str),
+                          "`_get_reshape_info` only supports string input.")
+        from openvino.tools.benchmark.utils.utils import parse_input_parameters
+        from openvino.runtime import PartialShape
+
+        inputs = self.ie_network.inputs
+        input_names = [port.any_name for port in inputs]
+        inputs_info = [(i.any_name, i.node.friendly_name, i.partial_shape) for i in inputs]
+        shape_map = parse_input_parameters(shapes, input_names=input_names)
+        reshape = False
+        input_shapes = {}
+        for name, node_name, shape in inputs_info:
+            new_shape = None
+            if name in shape_map:
+                new_shape = PartialShape(shape_map[name])
+            elif node_name in shape_map:
+                new_shape = PartialShape(shape_map[node_name])
+
+            if new_shape is None:
+                input_shapes[name] = shape
+            else:
+                if new_shape != shape:
+                    reshape = True
+                input_shapes[name] = new_shape
+
+        return input_shapes, reshape
+
     def _save(self, path):
         """
         Save OpenVINOModel to local as xml and bin file
 
         :param path: Directory to save the model.
         """
         self._model_exists_or_err()
```

## bigdl/nano/deps/openvino/pytorch/model.py

```diff
@@ -28,15 +28,16 @@
 from bigdl.nano.pytorch.context_manager import generate_context_manager
 from bigdl.nano.utils.pytorch import patch_attrs_from_model_to_object
 
 
 class PytorchOpenVINOModel(AcceleratedLightningModule):
     def __init__(self, model, input_sample=None, precision='fp32',
                  thread_num=None, device='CPU', dynamic_axes=True,
-                 logging=True, config=None, output_tensors=True, **kwargs):
+                 logging=True, config=None, output_tensors=True,
+                 shapes=None, **kwargs):
         """
         Create a OpenVINO model from pytorch.
 
         :param model: Pytorch model to be converted to OpenVINO for inference or
                       path to Openvino saved model.
         :param input_sample: A set of inputs for trace, defaults to None if you have trace before or
                              model is a LightningModule with any dataloader attached,
@@ -61,14 +62,18 @@
                              | are axis names. If a list, each element is an axis index.
 
                              If accelerator != 'openvino'/'onnxruntime', it will be ignored.
         :param logging: whether to log detailed information of model conversion. default: True.
         :param config: The config to be inputted in core.compile_model.
         :param output_tensors: boolean, default to True and output of the model will be Tensors. If
                                output_tensors=False, output of the OpenVINO model will be ndarray.
+        :param shapes: input shape. For example, 'input1[1,3,224,224],input2[1,4]',
+                       '[1,3,224,224]'. This parameter affect model Parameter shape, can be
+                       dynamic. For dynamic dimesions use symbol `?`, `-1` or range `low.. up`.'.
+                       Only valid for openvino model, otherwise will be ignored.
         :param **kwargs: will be passed to torch.onnx.export function or model optimizer function.
         """
         ov_model_path = model
         with TemporaryDirectory() as tmpdir:
             tmpdir = Path(tmpdir)
             if isinstance(model, torch.nn.Module):
                 # cope with dynamic axes for GPU
@@ -86,15 +91,16 @@
                        logging=logging, **kwargs)
                 ov_model_path = tmpdir / 'tmp.xml'
 
             self.ov_model = OpenVINOModel(ov_model_path,
                                           device=device,
                                           precision=precision,
                                           thread_num=thread_num,
-                                          config=config)
+                                          config=config,
+                                          shapes=shapes)
             super().__init__(None)
         self._nano_context_manager = generate_context_manager(accelerator="openvino",
                                                               precision="fp32",
                                                               thread_num=thread_num)
         if isinstance(model, torch.nn.Module):
             # patch original model's attr to current new model
             patch_attrs_from_model_to_object(model, self)
@@ -116,29 +122,32 @@
         outputs = list(outputs.values())
         if self.output_tensors:
             outputs = self.numpy_to_tensors(outputs)
         elif len(outputs) == 1:
             outputs = outputs[0]
         return outputs
 
+    def reshape(self, shapes):
+        return self.ov_model.reshape(shapes=shapes)
+
     @property
     def status(self):
         status = super().status
         status.update({"xml_path": 'ov_saved_model.xml',
                        "weight_path": 'ov_saved_model.bin',
                        "config": self.ov_model.final_config,
                        "device": self.ov_model._device})
         return status
 
     @property  # type: ignore
     def forward_args(self):
         return self.ov_model.forward_args
 
     @staticmethod
-    def _load(path, device=None):
+    def _load(path, device=None, cache_dir=None, shapes=None):
         """
         Load an OpenVINO model for inference from directory.
 
         :param path: Path to model to be loaded.
         :param device: A string represents the device of the inference.
         :return: PytorchOpenVINOModel model for OpenVINO inference.
         """
@@ -152,20 +161,23 @@
         xml_path = Path(path) / status['xml_path']
         thread_num = None
         config = status.get('config', {})
         if "CPU_THREADS_NUM" in config:
             thread_num = int(config["CPU_THREADS_NUM"])
         elif "INFERENCE_NUM_THREADS" in config:
             thread_num = int(config["INFERENCE_NUM_THREADS"])
+        if cache_dir is not None:
+            config["CACHE_DIR"] = cache_dir
         if device is None:
             device = status.get('device', 'CPU')
         return PytorchOpenVINOModel(xml_path,
                                     config=config,
                                     thread_num=thread_num,
-                                    device=device)
+                                    device=device,
+                                    shapes=shapes)
 
     def pot(self,
             dataloader,
             metric=None,
             higher_better=True,
             drop_type="relative",
             maximal_drop=0.999,
```

## bigdl/nano/deps/openvino/tf/model.py

```diff
@@ -34,15 +34,15 @@
 from .dataloader import KerasOpenVINODataLoader
 from .metric import KerasOpenVINOMetric
 
 
 class KerasOpenVINOModel(KerasOptimizedModel):
     def __init__(self, model, input_spec=None, precision='fp32',
                  thread_num=None, device='CPU', config=None,
-                 logging=True, **kwargs):
+                 logging=True, shapes=None, **kwargs):
         """
         Create a OpenVINO model from Keras.
 
         :param model: Keras model to be converted to OpenVINO for inference or
                       path to Openvino saved model.
         :param input_spec: A (tuple or list of) tf.TensorSpec or numpy array defining
                            the shape/dtype of the input
@@ -52,14 +52,18 @@
                     inference. default: None.
         :param device: A string represents the device of the inference. Default to 'CPU'.
                        'CPU', 'GPU' and 'VPUX' are supported for now.
         :param config: The config to be inputted in core.compile_model.
                        inference. default: None.
         :param logging: whether to log detailed information of model conversion.
                         default: True.
+        :param shapes: input shape. For example, 'input1[1,3,224,224],input2[1,4]',
+                       '[1,3,224,224]'. This parameter affect model Parameter shape, can be
+                       dynamic. For dynamic dimesions use symbol `?`, `-1` or range `low.. up`.'.
+                       Only valid for openvino model, otherwise will be ignored.
         :param **kwargs: will be passed to model optimizer function.
         """
         super().__init__()
         ov_model_path = model
         with TemporaryDirectory() as tmp_dir:
             tmp_dir = Path(tmp_dir)
             if isinstance(model, tf.keras.Model):
@@ -76,15 +80,16 @@
                        logging=logging,
                        **kwargs)
                 ov_model_path = tmp_dir / 'tmp.xml'
             self.ov_model = OpenVINOModel(ov_model_path,
                                           device=device,
                                           precision=precision,
                                           thread_num=thread_num,
-                                          config=config)
+                                          config=config,
+                                          shapes=shapes)
 
     def preprocess(self, args: Sequence[Any], kwargs: Dict[str, Any]):
         self.ov_model._model_exists_or_err()
         # todo: We should perform dtype conversion based on the
         # dtype of the arguments that the model expects
         inputs = args if self._mode == "arg" else [kwargs[name] for name in self._arg_names]
         inputs = convert_all(inputs, types="numpy", dtypes=np.float32)
@@ -137,15 +142,15 @@
                                      config=config, thread_num=thread_num,
                                      device=self.ov_model._device)
         q_model._mode = self._mode
         q_model._arg_names = self._arg_names
         return q_model
 
     @staticmethod
-    def _load(path, device=None):
+    def _load(path, device=None, cache_dir=None, shapes=None):
         """
         Load an OpenVINO model for inference from directory.
 
         :param path: Path to model to be loaded.
         :param device: A string represents the device of the inference.
         :return: KerasOpenVINOModel model for OpenVINO inference.
         """
@@ -159,20 +164,23 @@
         xml_path = Path(path) / status['xml_path']
         thread_num = None
         config = status.get('config', {})
         if "CPU_THREADS_NUM" in config:
             thread_num = int(config["CPU_THREADS_NUM"])
         elif "INFERENCE_NUM_THREADS" in config:
             thread_num = int(config["INFERENCE_NUM_THREADS"])
+        if cache_dir is not None:
+            config["CACHE_DIR"] = cache_dir
         if device is None:
             device = status.get('device', 'CPU')
         model = KerasOpenVINOModel(xml_path,
                                    config=status['config'],
                                    thread_num=thread_num,
-                                   device=device)
+                                   device=device,
+                                   shapes=shapes)
         with open(Path(path) / status['attr_path'], "rb") as f:
             attrs = pickle.load(f)
         for attr_name, attr_value in attrs.items():
             setattr(model, attr_name, attr_value)
         if os.path.exists(Path(path) / status['compile_path']):
             with open(Path(path) / status['compile_path'], "rb") as f:
                 kwargs = pickle.load(f)
```

## bigdl/nano/pytorch/inference/optimizer.py

```diff
@@ -1255,15 +1255,15 @@
                to load the compressed file if compression is set other than "fp32".
                Currently, "bf16" and "fp32"(default) are supported.
         """
         save_model(model, path, compression)
 
     @staticmethod
     def load(path, model: Optional[nn.Module] = None, input_sample=None,
-             inplace=False, device=None):
+             inplace=False, device=None, cache_dir=None, shapes=None):
         """
         Load a model from local.
 
         :param path: Path to model to be loaded. Path should be a directory.
         :param model: Required FP32 model to load pytorch model, it is needed if:
                1. you accelerate the model with accelerator=None by
                InferenceOptimizer.trace()/InferenceOptimizer.quantize().
@@ -1277,19 +1277,27 @@
                This parameter is needed if:
                1. saving model is accelerated by INC IPEX quantization.
                2. saving model is accelerated by JIT and you set compression='bf16'
                when saving.
         :param inplace: whether to perform inplace optimization. Default: ``False``.
         :param device: A string represents the device of the inference. Default to None.
                Only valid for openvino model, otherwise will be ignored.
+        :param cache_dir: A directory for OpenVINO to cache the model. Default to None.
+               Only valid for openvino model, otherwise will be ignored.
+        :param shapes: input shape. For example, 'input1[1,3,224,224],input2[1,4]',
+               '[1,3,224,224]'. This parameter affect model Parameter shape, can be
+               dynamic. For dynamic dimesions use symbol `?`, `-1` or range `low.. up`.'.
+               Default to None, which means you don't want to reshape the model inputs.
+               Only valid for openvino model, otherwise will be ignored.
         :return: Model with different acceleration(None/OpenVINO/ONNX Runtime/JIT) or
                  precision(FP32/FP16/BF16/INT8).
         """
         return load_model(path, model, input_sample=input_sample,
-                          inplace=inplace, device=device)
+                          inplace=inplace, device=device, cache_dir=cache_dir,
+                          shapes=shapes)
 
     @staticmethod
     def to_multi_instance(model: nn.Module, num_processes: int = 4,
                           cores_per_process: int = None,
                           cpu_for_each_process: List[List[int]] = None) -> _MultiInstanceModel:
         """
         Transform a model to multi-instance inference model.
```

## bigdl/nano/utils/pytorch/load.py

```diff
@@ -24,15 +24,15 @@
 
 from bigdl.nano.utils.common import invalidInputError
 from bigdl.nano.utils.pytorch import patch_attrs_from_model_to_object, \
     transform_state_dict_to_dtype
 
 
 def load_model(path, model: nn.Module = None, input_sample=None,
-               inplace=False, device=None):
+               inplace=False, device=None, cache_dir=None, shapes=None):
     """
     Load a model from local.
 
     :param path: Path to model to be loaded. Path should be a directory.
     :param model: Required FP32 model to load pytorch model, it is needed if:
                1. you accelerated the model with accelerator=None by
                InferenceOptimizer.trace/InferenceOptimizer.quantize.
@@ -41,14 +41,20 @@
                This parameter is needed if:
                1. saving model is accelerated by INC IPEX quantization.
                2. saving model is accelerated by JIT and you set compression='bf16'
                when saving.
     :param inplace: whether to perform inplace optimization. Default: ``False``.
     :param device: A string represents the device of the inference. Default to None.
                    Only valid for openvino model, otherwise will be ignored.
+    :param cache_dir: A directory for OpenVINO to cache the model. Default to None.
+                      Only valid for openvino model, otherwise will be ignored.
+    :param shapes: input shape. For example, 'input1[1,3,224,224],input2[1,4]',
+               '[1,3,224,224]'. This parameter affect model Parameter shape, can be
+               dynamic. For dynamic dimesions use symbol `?`, `-1` or range `low.. up`.'.
+               Only valid for openvino model, otherwise will be ignored.
     :return: Model with different acceleration(None/OpenVINO/ONNX Runtime/JIT) or
                 precision(FP32/FP16/BF16/INT8).
     """
     from bigdl.nano.pytorch.amp.amp_api import load_bf16_model
     from bigdl.nano.pytorch.low_precision.jit_int8_api import load_pytorchjitint8_model
     from bigdl.nano.pytorch.context_manager import generate_context_manager
     from bigdl.nano.deps.openvino.openvino_api import load_openvino_model
@@ -64,15 +70,15 @@
     if not meta_path.exists():
         invalidInputError(False, "File {} is required to load model.".format(str(meta_path)))
     with open(meta_path, 'r') as f:
         metadata = yaml.safe_load(f)
     model_type = metadata.get('ModelType', None)
     result = None
     if model_type == 'PytorchOpenVINOModel':
-        result = load_openvino_model(path, device=device)
+        result = load_openvino_model(path, device=device, cache_dir=cache_dir, shapes=shapes)
     if model_type == 'PytorchONNXRuntimeModel':
         result = load_onnxruntime_model(path)
     if model_type == 'PytorchQuantizedModel':
         result = load_inc_model(path, model, 'pytorch', input_sample=input_sample)
     if model_type == 'PytorchIPEXJITModel':
         result = load_ipexjit_model(path, model, inplace=inplace,
                                     input_sample=input_sample)
```

## Comparing `bigdl_nano-2.3.0b20230416.data/scripts/bigdl-nano-init` & `bigdl_nano-2.3.0b20230417.data/scripts/bigdl-nano-init`

 * *Files identical despite different names*

## Comparing `bigdl_nano-2.3.0b20230416.data/scripts/bigdl-nano-init.ps1` & `bigdl_nano-2.3.0b20230417.data/scripts/bigdl-nano-init.ps1`

 * *Files identical despite different names*

## Comparing `bigdl_nano-2.3.0b20230416.dist-info/METADATA` & `bigdl_nano-2.3.0b20230417.dist-info/METADATA`

 * *Files 0% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: bigdl-nano
-Version: 2.3.0b20230416
+Version: 2.3.0b20230417
 Summary: High-performance scalable acceleration components for intel.
 Home-page: https://github.com/intel-analytics/BigDL
 Author: BigDL Authors
 Author-email: bigdl-user-group@googlegroups.com
 License: UNKNOWN
 Platform: UNKNOWN
 Description-Content-Type: text/markdown
```

## Comparing `bigdl_nano-2.3.0b20230416.dist-info/RECORD` & `bigdl_nano-2.3.0b20230417.dist-info/RECORD`

 * *Files 2% similar despite different names*

```diff
@@ -73,28 +73,28 @@
 bigdl/nano/deps/onnxruntime/pytorch/__init__.py,sha256=b2IXvVqQ5cItki021h8s3ymW12RPu8QNPprq4Mn3bDM,586
 bigdl/nano/deps/onnxruntime/pytorch/pytorch_onnxruntime_model.py,sha256=PHoQMZsvg-kPlXPnBYDoLxk55WhHh3yBrNpWGTka_0o,7854
 bigdl/nano/deps/onnxruntime/tensorflow/__init__.py,sha256=b2IXvVqQ5cItki021h8s3ymW12RPu8QNPprq4Mn3bDM,586
 bigdl/nano/deps/onnxruntime/tensorflow/model.py,sha256=Cv0C3B18T9Sj1GWnHgnxOIU9_YhudrTwYZsbAuyXZH8,7852
 bigdl/nano/deps/onnxsim/__init__.py,sha256=b2IXvVqQ5cItki021h8s3ymW12RPu8QNPprq4Mn3bDM,586
 bigdl/nano/deps/onnxsim/onnxsim_api.py,sha256=wywKDXPEO7bi_MY12UkoncEADvnhztqoqyJp8xo5ubc,1105
 bigdl/nano/deps/openvino/__init__.py,sha256=b2IXvVqQ5cItki021h8s3ymW12RPu8QNPprq4Mn3bDM,586
-bigdl/nano/deps/openvino/openvino_api.py,sha256=TNLXmDBJIYybwneqzOcP7b69vfOGMW6yK1fB_y0fIX8,6365
+bigdl/nano/deps/openvino/openvino_api.py,sha256=n53VlK4kcDdwS_HYcV4GAoXjvooxDqeHGNsBqHZ6cqk,6986
 bigdl/nano/deps/openvino/core/__init__.py,sha256=kSQ0UT3QO1LNOONyFMu6MjG7MVx_Cf_131OBy2e_jhw,872
 bigdl/nano/deps/openvino/core/metric.py,sha256=KCEAgwrKm_QFNrQvM51lsKZt7k1njT-jtyJlqgTEZ6I,2129
-bigdl/nano/deps/openvino/core/model.py,sha256=lbKANq1lt9rbgEhYs6D_HBKMT8COVG-yQqDX4cRBN4k,10572
+bigdl/nano/deps/openvino/core/model.py,sha256=rfBTcF7cP5d6pOJg_9x71XYvg5oNLBku2c0VsSf04-s,14225
 bigdl/nano/deps/openvino/core/utils.py,sha256=kelcmlkhHp8m3NYme6ZD5YCgL9i1iguR2tphy2eCv8U,4075
 bigdl/nano/deps/openvino/pytorch/__init__.py,sha256=b2IXvVqQ5cItki021h8s3ymW12RPu8QNPprq4Mn3bDM,586
 bigdl/nano/deps/openvino/pytorch/dataloader.py,sha256=7DNz7QvQSySrVwowGizzyNfJqXOXoh1UsL0VOiM8yR0,1519
 bigdl/nano/deps/openvino/pytorch/metric.py,sha256=hM3nhIeeK0rOABk3s3mzQa3q4xrqeVX_CK0Aq2be5Gw,1668
-bigdl/nano/deps/openvino/pytorch/model.py,sha256=7ll5r4_LbzoYvvW2bxZE9wXKN9c_MR_ftNV6rur8Huo,12317
+bigdl/nano/deps/openvino/pytorch/model.py,sha256=RzX8sDT8Yx1AJFnXBZjoVXlW0BwO2YLz0j4FVaUAJic,13001
 bigdl/nano/deps/openvino/pytorch/utils.py,sha256=B_bX2uGKVwNaJEY6i55tR7j2vI0yHsD75bw0HLxA_lk,2616
 bigdl/nano/deps/openvino/tf/__init__.py,sha256=b2IXvVqQ5cItki021h8s3ymW12RPu8QNPprq4Mn3bDM,586
 bigdl/nano/deps/openvino/tf/dataloader.py,sha256=G9Ti71qinxqqMjO7BdhBHe8kBSKydIBd54PfzTa0IqI,1845
 bigdl/nano/deps/openvino/tf/metric.py,sha256=ey7xQUSOQtAv5k_45JB4FUrKWbckaomxmqUx5OwkmuM,1499
-bigdl/nano/deps/openvino/tf/model.py,sha256=ugB-I2RinXc43TrMF2MfqdDqR77chQy3JfwMjV-hVpo,9735
+bigdl/nano/deps/openvino/tf/model.py,sha256=OAB1QKT0sC-aKNuAC-4-5mDBGhT_xxi_Xajr-TOJb1Q,10317
 bigdl/nano/deps/openvino/tf/utils.py,sha256=AqtLgumFpX4LHYEACWrw4ZLi8-Pujmjj2F93efzeSnw,1676
 bigdl/nano/deps/ray/__init__.py,sha256=b2IXvVqQ5cItki021h8s3ymW12RPu8QNPprq4Mn3bDM,586
 bigdl/nano/deps/ray/ray_api.py,sha256=4FwcTfu70nR89SWykO7G9ZEgLhNQNiU6VClIa3mScrc,1265
 bigdl/nano/deps/ray/ray_backend.py,sha256=qUAW3MkYxV4Tr-AcdFN1d8L0AWGBQJCcGMM5Lu0-lE0,1530
 bigdl/nano/deps/ray/ray_distributed.py,sha256=oXR3JlZzXGZtUTbmOBQfQlerchwv388lbMwhqPWcjKE,18650
 bigdl/nano/deps/ray/ray_envbase.py,sha256=Q_F76GckR7_W8atNR-f4cD6OJvwFC-gstX0XmxgdlCo,3705
 bigdl/nano/k8s/__init__.py,sha256=Sjb3PUJAupart-VZ3ccAh6j7tXC1mNrv_BTyLlpwpaA,618
@@ -114,15 +114,15 @@
 bigdl/nano/pytorch/amp/__init__.py,sha256=5T_pNFHbS-EdK7nlbJJqb4JlCvUnPQpO-sxVZuaP6Ys,609
 bigdl/nano/pytorch/amp/amp_api.py,sha256=RSZda43RuQZJB3sfvMR58WIHrj_RyHQHn3NOc0O_HSQ,805
 bigdl/nano/pytorch/amp/bfloat16.py,sha256=Qw9ZXUxDeIgBFfPNedS9PwSi7FPl1bG-9HrloKyz_lw,9569
 bigdl/nano/pytorch/encryption/__init__.py,sha256=4e0eEjjj3iNwnCRzLtzVjS27oH-CA1ws6TJXnuUwNg8,640
 bigdl/nano/pytorch/encryption/encryption.py,sha256=UIiNtbyZ0GFlkirOHX2hOzxKXtYJ6g56SQ2lJvO40kY,6480
 bigdl/nano/pytorch/inference/__init__.py,sha256=PlFS2XblVRBXTai86gEV79sQWEJLgaOyDnjdLYNKxTA,661
 bigdl/nano/pytorch/inference/multi_instance.py,sha256=XCMQRg1BHfuQWxNTtsHpplZfSNSj0rEO71if67OsR-I,4231
-bigdl/nano/pytorch/inference/optimizer.py,sha256=JKmivjU9QlKpFP6MXTdojwkrRy1JDPx2kcVTp9u5UIU,86189
+bigdl/nano/pytorch/inference/optimizer.py,sha256=stRj_ra-FZPTugYuP4B91JLmSenLytiV1n2NPlCeYXU,86860
 bigdl/nano/pytorch/inference/pipeline.py,sha256=lpU1OyoIjYsVf6nw0IF8JH82Z228_WSMj_qZtww1F6A,4593
 bigdl/nano/pytorch/low_precision/jit_int8_api.py,sha256=wPcuXWKUmhBc45cft7PvRFQjM_rRRzhDK0LKTm2zYPc,3015
 bigdl/nano/pytorch/low_precision/jit_int8_model.py,sha256=XKY0Js0ZeXurOt6Kcl--FHX4zyzbzC5XTAcB0hooVK8,9651
 bigdl/nano/pytorch/optim/__init__.py,sha256=JWc3YVybOcyixkTxAB2QVN9l4KZC7BXg8D2myUs2P-w,646
 bigdl/nano/pytorch/optim/sparseadam.py,sha256=22GGm0Kh2idtAgEj5mn5asMYc3CoKbbE-gwPqtXwrgA,8351
 bigdl/nano/pytorch/patching/__init__.py,sha256=LGg-BpIbWHdj_LNe4Px1m2lU-Y9LFAmWtctRF9wbCFM,804
 bigdl/nano/pytorch/patching/dtype_patching/__init__.py,sha256=P99b-m_UygHUv-c1jsfE2Q0dtGkbM_mt_GFio7bBFlQ,627
@@ -196,29 +196,29 @@
 bigdl/nano/utils/pytorch/channel_last.py,sha256=iDbh_s8yFIFq0i1JRyCCYIJf67FRrf7FNU5j1js05NY,4527
 bigdl/nano/utils/pytorch/check_deps.py,sha256=oFq4BvkXQgJdpQBVwYwCd1ZN64Gfu16rmC55AO5KU-0,1807
 bigdl/nano/utils/pytorch/convert.py,sha256=kTQRSN7RZSoPXm7Q77wxUtGVBZ6KKz6pXNuFf36mobA,3358
 bigdl/nano/utils/pytorch/dataloader.py,sha256=pYC4dYKKQLH8XFtCqJ66pvhSyGBSNfM1JFTUuyf6jfQ,6234
 bigdl/nano/utils/pytorch/dataset.py,sha256=8niaxA5SMmet_nVFiO9NMeL4hesCJsJxjhNJwRxfouc,1321
 bigdl/nano/utils/pytorch/input_sample.py,sha256=1wecir3d9uNn39o_StO9GZHr3TMCRC5G4eK4ykIkF-Q,3881
 bigdl/nano/utils/pytorch/inspect.py,sha256=z013opp8CfvOHFFDju2tW9v6vhdjLwQ5huychXYKpiU,4952
-bigdl/nano/utils/pytorch/load.py,sha256=-f3SEbHDAxeNN24E-esY4GPQaDdGZFdSnpDlqkE2MI8,5714
+bigdl/nano/utils/pytorch/load.py,sha256=LxJ5pQd9Ijfc-KreuihtF1p__Gl25O5a2Noqcm1UHJA,6270
 bigdl/nano/utils/pytorch/metric.py,sha256=7TFBw2F5t_sh-2p0XbbUgUujZULBIwBMFIRt5FV4ATA,1391
 bigdl/nano/utils/pytorch/model_info.py,sha256=IT4RYtgB-YukrEudgu5j3BKDnCBlOIuKo_EyFQuG0G4,5531
 bigdl/nano/utils/pytorch/save.py,sha256=kGCz6w1Dhx4jAgo3A2TAaFv9zL6pxdEeJCJMEnGyX6k,2878
 bigdl/nano/utils/pytorch/version.py,sha256=-zK3eeKIOBgi4HAsUYTumux4axNcx8gYrh61TRm8i-4,1189
 bigdl/nano/utils/pytorch/xpu.py,sha256=anqzDwqy701n-hmSY75G7TrM56WZ6Vdcgbb53q74F6I,1012
 bigdl/nano/utils/tf/__init__.py,sha256=wxh1M-4H8NwLSNhiipdZcXs8gtycV3Cs2DcVPRUnuAE,1057
 bigdl/nano/utils/tf/attributes.py,sha256=AkRSYw0bmdpLwnWZjRXsaIVrDW9H2TJpBB3Tq-RVoGg,4300
 bigdl/nano/utils/tf/backend.py,sha256=CfI_33A-2Na8R462k592F0FlAkwu0lTKzedf_SXyUgQ,2816
 bigdl/nano/utils/tf/data.py,sha256=HyrSXuDeSC-b2X8yP7RBTTKgvLDhV5OqXf7eFOte6nc,7421
 bigdl/nano/utils/tf/preprocess.py,sha256=DHukkdJUa-3z0jK63okaJ0vhbRAJipAoBUpsyS4P93k,2582
 bigdl/nano/utils/tf/subprocess_worker.py,sha256=LitCgfBQdnMqOmGuio4y58Mh9xCoxvn3JVS0INek5mE,1347
 bigdl/nano/utils/tf/version.py,sha256=IN7ZGJJPKSUAJN2LmiJgO_C6cZM8d9023DjcwZ0x9sg,823
-bigdl_nano-2.3.0b20230416.data/scripts/bigdl-nano-init,sha256=A-cN-f_uxGLK3UX7AkwdCpcaMij9SE-rbySsCZRPAPY,12068
-bigdl_nano-2.3.0b20230416.data/scripts/bigdl-nano-init.ps1,sha256=kX83Ue2ZJgibvddidAHzQ5zhbGlHntKlTcK5lvNmkV4,909
-bigdl_nano-2.3.0b20230416.data/scripts/bigdl-nano-unset-env,sha256=rWzU73m1pflJazC6ulhItByaoudgSa8XlUAJVj3W02c,214
-bigdl_nano-2.3.0b20230416.data/scripts/bigdl-nano-unset-env.ps1,sha256=amIge9q2-1oumygXfW00qeYejEdVMESNUferj5B7txU,127
-bigdl_nano-2.3.0b20230416.dist-info/METADATA,sha256=FI3HPsLlV712vkoaf7r8g6hkfU-WAv2uhL3URwNcBbM,10112
-bigdl_nano-2.3.0b20230416.dist-info/WHEEL,sha256=bC8mYJUOJCh5KnyEeT6W_BCQYi3v39D3z64Vy_sFvVg,98
-bigdl_nano-2.3.0b20230416.dist-info/entry_points.txt,sha256=NJqjgi9adpmsUUYPXsd7LzSBdoN1nYjeOyFi9Wih_oU,54
-bigdl_nano-2.3.0b20230416.dist-info/top_level.txt,sha256=iGuLfZARD_qANcIMfy0tbbrC3EtCg6BSiH8icc3dLWs,6
-bigdl_nano-2.3.0b20230416.dist-info/RECORD,,
+bigdl_nano-2.3.0b20230417.data/scripts/bigdl-nano-init,sha256=A-cN-f_uxGLK3UX7AkwdCpcaMij9SE-rbySsCZRPAPY,12068
+bigdl_nano-2.3.0b20230417.data/scripts/bigdl-nano-init.ps1,sha256=kX83Ue2ZJgibvddidAHzQ5zhbGlHntKlTcK5lvNmkV4,909
+bigdl_nano-2.3.0b20230417.data/scripts/bigdl-nano-unset-env,sha256=rWzU73m1pflJazC6ulhItByaoudgSa8XlUAJVj3W02c,214
+bigdl_nano-2.3.0b20230417.data/scripts/bigdl-nano-unset-env.ps1,sha256=amIge9q2-1oumygXfW00qeYejEdVMESNUferj5B7txU,127
+bigdl_nano-2.3.0b20230417.dist-info/METADATA,sha256=APNAKu5K9-a9ywFtv17Lf-xh_kA_l2JxcPxhnW1mAeU,10112
+bigdl_nano-2.3.0b20230417.dist-info/WHEEL,sha256=bC8mYJUOJCh5KnyEeT6W_BCQYi3v39D3z64Vy_sFvVg,98
+bigdl_nano-2.3.0b20230417.dist-info/entry_points.txt,sha256=NJqjgi9adpmsUUYPXsd7LzSBdoN1nYjeOyFi9Wih_oU,54
+bigdl_nano-2.3.0b20230417.dist-info/top_level.txt,sha256=iGuLfZARD_qANcIMfy0tbbrC3EtCg6BSiH8icc3dLWs,6
+bigdl_nano-2.3.0b20230417.dist-info/RECORD,,
```

