# Comparing `tmp/nucliadb_sdk-2.7.0.post167-py3-none-any.whl.zip` & `tmp/nucliadb_sdk-2.7.0.post168-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,26 +1,29 @@
-Zip file size: 30054 bytes, number of entries: 24
--rw-r--r--  2.0 unx     1440 b- defN 23-Apr-17 06:53 nucliadb_sdk/__init__.py
--rw-r--r--  2.0 unx    16458 b- defN 23-Apr-17 06:53 nucliadb_sdk/client.py
--rw-r--r--  2.0 unx     1051 b- defN 23-Apr-17 06:53 nucliadb_sdk/entities.py
--rw-r--r--  2.0 unx      978 b- defN 23-Apr-17 06:53 nucliadb_sdk/file.py
--rw-r--r--  2.0 unx    13121 b- defN 23-Apr-17 06:53 nucliadb_sdk/knowledgebox.py
--rw-r--r--  2.0 unx     1302 b- defN 23-Apr-17 06:53 nucliadb_sdk/labels.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-17 06:53 nucliadb_sdk/py.typed
--rw-r--r--  2.0 unx    14188 b- defN 23-Apr-17 06:53 nucliadb_sdk/resource.py
--rw-r--r--  2.0 unx     3763 b- defN 23-Apr-17 06:53 nucliadb_sdk/search.py
--rw-r--r--  2.0 unx     4300 b- defN 23-Apr-17 06:53 nucliadb_sdk/utils.py
--rw-r--r--  2.0 unx     1611 b- defN 23-Apr-17 06:53 nucliadb_sdk/vectors.py
--rw-r--r--  2.0 unx      833 b- defN 23-Apr-17 06:53 nucliadb_sdk/tests/__init__.py
--rw-r--r--  2.0 unx      891 b- defN 23-Apr-17 06:53 nucliadb_sdk/tests/conftest.py
--rw-r--r--  2.0 unx     2778 b- defN 23-Apr-17 06:53 nucliadb_sdk/tests/fixtures.py
--rw-r--r--  2.0 unx     1183 b- defN 23-Apr-17 06:53 nucliadb_sdk/tests/test_create.py
--rw-r--r--  2.0 unx     1715 b- defN 23-Apr-17 06:53 nucliadb_sdk/tests/test_dict_resource.py
--rw-r--r--  2.0 unx    14102 b- defN 23-Apr-17 06:53 nucliadb_sdk/tests/test_search_resource.py
--rw-r--r--  2.0 unx     3909 b- defN 23-Apr-17 06:53 nucliadb_sdk/tests/test_set_resource.py
--rw-r--r--  2.0 unx     1429 b- defN 23-Apr-17 06:53 nucliadb_sdk/tests/test_vectors.py
--rw-r--r--  2.0 unx      691 b- defN 23-Apr-17 06:55 nucliadb_sdk-2.7.0.post167.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 23-Apr-17 06:55 nucliadb_sdk-2.7.0.post167.dist-info/WHEEL
--rw-r--r--  2.0 unx       13 b- defN 23-Apr-17 06:55 nucliadb_sdk-2.7.0.post167.dist-info/top_level.txt
--rw-r--r--  2.0 unx        1 b- defN 23-Apr-17 06:54 nucliadb_sdk-2.7.0.post167.dist-info/zip-safe
--rw-rw-r--  2.0 unx     2058 b- defN 23-Apr-17 06:55 nucliadb_sdk-2.7.0.post167.dist-info/RECORD
-24 files, 87907 bytes uncompressed, 26700 bytes compressed:  69.6%
+Zip file size: 34338 bytes, number of entries: 27
+-rw-r--r--  2.0 unx     1440 b- defN 23-Apr-17 10:29 nucliadb_sdk/__init__.py
+-rw-r--r--  2.0 unx    18079 b- defN 23-Apr-17 10:29 nucliadb_sdk/client.py
+-rw-r--r--  2.0 unx     1051 b- defN 23-Apr-17 10:29 nucliadb_sdk/entities.py
+-rw-r--r--  2.0 unx      978 b- defN 23-Apr-17 10:29 nucliadb_sdk/file.py
+-rw-r--r--  2.0 unx     1937 b- defN 23-Apr-17 10:29 nucliadb_sdk/find.py
+-rw-r--r--  2.0 unx    19218 b- defN 23-Apr-17 10:29 nucliadb_sdk/knowledgebox.py
+-rw-r--r--  2.0 unx     1302 b- defN 23-Apr-17 10:29 nucliadb_sdk/labels.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Apr-17 10:29 nucliadb_sdk/py.typed
+-rw-r--r--  2.0 unx    14486 b- defN 23-Apr-17 10:29 nucliadb_sdk/resource.py
+-rw-r--r--  2.0 unx     3763 b- defN 23-Apr-17 10:29 nucliadb_sdk/search.py
+-rw-r--r--  2.0 unx     4300 b- defN 23-Apr-17 10:29 nucliadb_sdk/utils.py
+-rw-r--r--  2.0 unx     1611 b- defN 23-Apr-17 10:29 nucliadb_sdk/vectors.py
+-rw-r--r--  2.0 unx      833 b- defN 23-Apr-17 10:29 nucliadb_sdk/tests/__init__.py
+-rw-r--r--  2.0 unx      891 b- defN 23-Apr-17 10:29 nucliadb_sdk/tests/conftest.py
+-rw-r--r--  2.0 unx     4511 b- defN 23-Apr-17 10:29 nucliadb_sdk/tests/fixtures.py
+-rw-r--r--  2.0 unx     1277 b- defN 23-Apr-17 10:29 nucliadb_sdk/tests/test_chat_resources.py
+-rw-r--r--  2.0 unx     1183 b- defN 23-Apr-17 10:29 nucliadb_sdk/tests/test_create.py
+-rw-r--r--  2.0 unx     1715 b- defN 23-Apr-17 10:29 nucliadb_sdk/tests/test_dict_resource.py
+-rw-r--r--  2.0 unx     1302 b- defN 23-Apr-17 10:29 nucliadb_sdk/tests/test_find_resources.py
+-rw-r--r--  2.0 unx    14102 b- defN 23-Apr-17 10:29 nucliadb_sdk/tests/test_search_resource.py
+-rw-r--r--  2.0 unx     3909 b- defN 23-Apr-17 10:29 nucliadb_sdk/tests/test_set_resource.py
+-rw-r--r--  2.0 unx     1429 b- defN 23-Apr-17 10:29 nucliadb_sdk/tests/test_vectors.py
+-rw-r--r--  2.0 unx      691 b- defN 23-Apr-17 10:31 nucliadb_sdk-2.7.0.post168.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 23-Apr-17 10:31 nucliadb_sdk-2.7.0.post168.dist-info/WHEEL
+-rw-r--r--  2.0 unx       13 b- defN 23-Apr-17 10:31 nucliadb_sdk-2.7.0.post168.dist-info/top_level.txt
+-rw-r--r--  2.0 unx        1 b- defN 23-Apr-17 10:30 nucliadb_sdk-2.7.0.post168.dist-info/zip-safe
+-rw-rw-r--  2.0 unx     2331 b- defN 23-Apr-17 10:31 nucliadb_sdk-2.7.0.post168.dist-info/RECORD
+27 files, 102445 bytes uncompressed, 30552 bytes compressed:  70.2%
```

## zipnote {}

```diff
@@ -6,14 +6,17 @@
 
 Filename: nucliadb_sdk/entities.py
 Comment: 
 
 Filename: nucliadb_sdk/file.py
 Comment: 
 
+Filename: nucliadb_sdk/find.py
+Comment: 
+
 Filename: nucliadb_sdk/knowledgebox.py
 Comment: 
 
 Filename: nucliadb_sdk/labels.py
 Comment: 
 
 Filename: nucliadb_sdk/py.typed
@@ -36,38 +39,44 @@
 
 Filename: nucliadb_sdk/tests/conftest.py
 Comment: 
 
 Filename: nucliadb_sdk/tests/fixtures.py
 Comment: 
 
+Filename: nucliadb_sdk/tests/test_chat_resources.py
+Comment: 
+
 Filename: nucliadb_sdk/tests/test_create.py
 Comment: 
 
 Filename: nucliadb_sdk/tests/test_dict_resource.py
 Comment: 
 
+Filename: nucliadb_sdk/tests/test_find_resources.py
+Comment: 
+
 Filename: nucliadb_sdk/tests/test_search_resource.py
 Comment: 
 
 Filename: nucliadb_sdk/tests/test_set_resource.py
 Comment: 
 
 Filename: nucliadb_sdk/tests/test_vectors.py
 Comment: 
 
-Filename: nucliadb_sdk-2.7.0.post167.dist-info/METADATA
+Filename: nucliadb_sdk-2.7.0.post168.dist-info/METADATA
 Comment: 
 
-Filename: nucliadb_sdk-2.7.0.post167.dist-info/WHEEL
+Filename: nucliadb_sdk-2.7.0.post168.dist-info/WHEEL
 Comment: 
 
-Filename: nucliadb_sdk-2.7.0.post167.dist-info/top_level.txt
+Filename: nucliadb_sdk-2.7.0.post168.dist-info/top_level.txt
 Comment: 
 
-Filename: nucliadb_sdk-2.7.0.post167.dist-info/zip-safe
+Filename: nucliadb_sdk-2.7.0.post168.dist-info/zip-safe
 Comment: 
 
-Filename: nucliadb_sdk-2.7.0.post167.dist-info/RECORD
+Filename: nucliadb_sdk-2.7.0.post168.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## nucliadb_sdk/client.py

```diff
@@ -24,15 +24,18 @@
 import httpx
 import requests
 
 from nucliadb_models.entities import KnowledgeBoxEntities
 from nucliadb_models.labels import KnowledgeBoxLabels
 from nucliadb_models.resource import Resource
 from nucliadb_models.search import (
+    ChatRequest,
+    FindRequest,
     KnowledgeboxCounters,
+    KnowledgeboxFindResults,
     KnowledgeboxSearchResults,
     SearchRequest,
 )
 from nucliadb_models.vectors import VectorSet, VectorSets
 from nucliadb_models.writer import (
     CreateResourcePayload,
     ResourceCreated,
@@ -43,14 +46,16 @@
 RESOURCE_PATH_BY_SLUG = "/slug/{slug}"
 SEARCH_PATH = "/search"
 CREATE_RESOURCE_PATH = "/resources"
 CREATE_VECTORSET = "/vectorset/{vectorset}"
 VECTORSETS = "/vectorsets"
 COUNTER = "/counters"
 SEARCH_URL = "/search"
+FIND_URL = "/find"
+CHAT_URL = "/chat"
 LABELS_URL = "/labelsets"
 ENTITIES_URL = "/entitiesgroups"
 DOWNLOAD_URL = "/{uri}"
 TUS_UPLOAD_URL = "/resource/{rid}/file/{field}/tusupload"
 
 
 class HTTPError(Exception):
@@ -62,78 +67,85 @@
     OSS = "OSS"
 
 
 class NucliaDBClient:
     api_key: Optional[str]
     environment: Environment
     session: httpx.Client
-    url: Optional[str]
+    url: str
+    search_url: str
 
     def __init__(
         self,
         *,
         environment: Environment = Environment.CLOUD,
         url: Optional[str] = None,
         api_key: Optional[str] = None,
         writer_host: Optional[str] = None,
         reader_host: Optional[str] = None,
         search_host: Optional[str] = None,
         train_host: Optional[str] = None,
     ):
         self.api_key = api_key
         self.environment = environment
-        self.url = url
 
         internal_hosts_set = all((writer_host, reader_host, search_host, train_host))
         url_set = bool(url)
 
-        if not (url_set or internal_hosts_set):
-            raise AttributeError("Either url or nucliadb services hosts must be set")
-
-        if url_set:
+        if url_set and url is not None:
             self.url = url
-        elif internal_hosts_set:
+        elif internal_hosts_set and writer_host is not None:
             self.url = writer_host
+        else:
+            raise AttributeError("Either url or nucliadb services hosts must be set")
 
         if environment == Environment.CLOUD and api_key is not None:
             reader_headers = {
                 "X-STF-SERVICEACCOUNT": f"Bearer {api_key}",
             }
             writer_headers = {
                 "X-STF-SERVICEACCOUNT": f"Bearer {api_key}",
+                "X-SYNCHRONOUS": "True",
             }
         elif environment == Environment.CLOUD and api_key is None:
             raise AttributeError("On Cloud you need to provide API Key")
         else:
             reader_headers = {
                 "X-NUCLIADB-ROLES": f"READER",
             }
             writer_headers = {
                 "X-NUCLIADB-ROLES": f"WRITER",
+                "X-SYNCHRONOUS": "True",
             }
 
         self.reader_session = httpx.Client(
             headers=reader_headers, base_url=reader_host or url  # type: ignore
         )
         self.async_reader_session = httpx.AsyncClient(
             headers=reader_headers, base_url=reader_host or url  # type: ignore
         )
         self.stream_session = requests.Session()
         self.stream_session.headers.update(reader_headers)
+        if search_host is None and url is None:
+            raise AttributeError("Either search_url or url needs to not be None")
+        elif search_host is not None:
+            self.search_url = search_host
+        elif url is not None:
+            self.search_url = url
         self.writer_session = httpx.Client(
             headers=writer_headers, base_url=writer_host or url  # type: ignore
         )
         self.async_writer_session = httpx.AsyncClient(
             headers=writer_headers, base_url=writer_host or url  # type: ignore
         )
         self.search_session = httpx.Client(
-            headers=reader_headers, base_url=search_host or url  # type: ignore
+            headers=reader_headers, base_url=self.search_url  # type: ignore
         )
         self.async_search_session = httpx.AsyncClient(
-            headers=reader_headers, base_url=search_host or url  # type: ignore
+            headers=reader_headers, base_url=self.search_url  # type: ignore
         )
         self.train_session = httpx.Client(
             headers=reader_headers, base_url=train_host or url  # type: ignore
         )
 
     def get_resource(self, id: str):
         url = RESOURCE_PATH.format(rid=id)
@@ -362,14 +374,44 @@
             url, content=request.json()
         )
         if response.status_code == 200:
             return KnowledgeboxSearchResults.parse_raw(response.content)
         else:
             raise HTTPError(f"Status code {response.status_code}: {response.text}")
 
+    def find(self, request: FindRequest):
+        url = FIND_URL
+
+        response: httpx.Response = self.search_session.post(url, content=request.json())
+        if response.status_code == 200:
+            return KnowledgeboxFindResults.parse_raw(response.content)
+        else:
+            raise HTTPError(f"Status code {response.status_code}: {response.text}")
+
+    async def async_find(self, request: FindRequest):
+        url = FIND_URL
+        response: httpx.Response = await self.async_search_session.post(
+            url, content=request.json()
+        )
+        if response.status_code == 200:
+            return KnowledgeboxFindResults.parse_raw(response.content)
+        else:
+            raise HTTPError(f"Status code {response.status_code}: {response.text}")
+
+    def chat(self, request: ChatRequest):
+        url = f"{self.search_url}{CHAT_URL}"
+        response: requests.Response = self.stream_session.post(
+            url, data=request.json(), stream=True
+        )
+        response
+        if response.status_code == 200:
+            return response
+        else:
+            raise HTTPError(f"Status code {response.status_code}: {response.text}")
+
     def download(self, uri: str) -> bytes:
         # uri has format
         # /kb/2a00d5b4-cfcc-48eb-85ac-d70bfd38b26d/resource/41d02aac4ade48098b23e38141807738/file/file/download/field
         # we need to remove the kb url
 
         uri_parts = uri.split("/")
         if len(uri_parts) < 9:
```

## nucliadb_sdk/knowledgebox.py

```diff
@@ -13,38 +13,51 @@
 # but WITHOUT ANY WARRANTY; without even the implied warranty of
 # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
 # GNU Affero General Public License for more details.
 #
 # You should have received a copy of the GNU Affero General Public License
 # along with this program. If not, see <http://www.gnu.org/licenses/>.
 
+import base64
 import os
+from datetime import datetime
 from typing import (
     TYPE_CHECKING,
     Any,
     AsyncIterable,
     Dict,
     Iterable,
     List,
     Optional,
+    Tuple,
     Union,
 )
 
+from nucliadb_models.common import FieldTypeName
 from nucliadb_models.labels import KnowledgeBoxLabels
 from nucliadb_models.labels import Label as NDBLabel
-from nucliadb_models.resource import Resource
+from nucliadb_models.resource import ExtractedDataTypeName, Resource
 from nucliadb_models.search import (
+    ChatOptions,
+    ChatRequest,
+    FindRequest,
+    KnowledgeboxFindResults,
     KnowledgeboxSearchResults,
+    Message,
+    Relations,
+    ResourceProperties,
     SearchOptions,
     SearchRequest,
 )
+from nucliadb_models.text import TextFormat
 from nucliadb_models.vectors import VectorSet, VectorSets
 from nucliadb_sdk.client import NucliaDBClient
 from nucliadb_sdk.entities import Entities
 from nucliadb_sdk.file import File
+from nucliadb_sdk.find import FindResult
 from nucliadb_sdk.labels import DEFAULT_LABELSET, Label, Labels, LabelSet, LabelType
 from nucliadb_sdk.resource import (
     create_resource,
     from_resource_to_payload,
     update_resource,
 )
 from nucliadb_sdk.search import SearchResult
@@ -142,14 +155,15 @@
         self.client.del_vectorset(key)
 
     async def async_upload(
         self,
         key: Optional[str] = None,
         binary: Optional[File] = None,
         text: Optional[str] = None,
+        format: Optional[TextFormat] = None,
         labels: Optional[Labels] = None,
         entities: Optional[Entities] = None,
         vectors: Optional[Vectors] = None,
     ):
         resource: Optional[Resource] = None
 
         if key is None:
@@ -164,28 +178,30 @@
         if vectors is not None and self.vectorsets is None:
             self.vectorsets = await self.client.async_get_vectorsets()
 
         if creating:
             create_payload = create_resource(
                 key=key,
                 text=text,
+                format=format,
                 binary=binary,
                 labels=labels,
                 entities=entities,
                 vectors=vectors,
                 vectorsets=self.vectorsets,
             )
             resp = await self.client.async_create_resource(create_payload)
             rid = resp.uuid
 
         else:
             assert resource is not None
 
             update_payload = update_resource(
                 text=text,
+                format=format,
                 binary=binary,
                 labels=labels,
                 entities=entities,
                 vectors=vectors,
                 resource=resource,
                 vectorsets=self.vectorsets,
             )
@@ -194,14 +210,15 @@
         return rid
 
     def upload(
         self,
         key: Optional[str] = None,
         binary: Optional[Union[File, str]] = None,
         text: Optional[str] = None,
+        format: Optional[TextFormat] = None,
         labels: Optional[Labels] = None,
         entities: Optional[Entities] = None,
         vectors: Optional[
             Union[Vectors, Dict[str, Union[ndarray, List[float]]]]
         ] = None,
     ) -> str:
         resource: Optional[Resource] = None
@@ -218,27 +235,29 @@
         if vectors is not None and self.vectorsets is None:
             self.vectorsets = self.client.get_vectorsets()
 
         if creating:
             create_payload = create_resource(
                 key=key,
                 text=text,
+                format=format,
                 binary=binary,
                 labels=labels,
                 entities=entities,
                 vectors=vectors,
                 vectorsets=self.vectorsets,
             )
             resp = self.client.create_resource(create_payload)
             rid = resp.uuid
 
         else:
             assert resource is not None
             update_payload = update_resource(
                 text=text,
+                format=format,
                 binary=binary,
                 labels=labels,
                 entities=entities,
                 vectors=vectors,
                 resource=resource,
                 vectorsets=self.vectorsets,
             )
@@ -332,14 +351,154 @@
         min_score: Optional[float] = 0.0,
     ):
         result = await self.client.async_search(
             self.build_search_request(text, filter, vector, vectorset, min_score)
         )
         return SearchResult(result, self.client)
 
+    def find(
+        self,
+        text: Optional[str] = None,
+        filter: Optional[List[Union[Label, str]]] = None,
+        vector: Optional[Union[ndarray, List[float]]] = None,
+        vectorset: Optional[str] = None,
+        min_score: Optional[float] = 0.0,
+    ):
+        result = self.client.find(
+            self.build_find_request(text, filter, vector, vectorset, min_score)
+        )
+        return FindResult(result)
+
+    async def async_find(
+        self,
+        text: Optional[str] = None,
+        filter: Optional[List[Union[Label, str]]] = None,
+        vector: Optional[Union[ndarray, List[float]]] = None,
+        vectorset: Optional[str] = None,
+        min_score: Optional[float] = 0.0,
+    ):
+        result = await self.client.async_find(
+            self.build_find_request(text, filter, vector, vectorset, min_score)
+        )
+        return FindResult(result)
+
+    def chat(
+        self,
+        text: str,
+        context: Optional[List[Message]] = None,
+        filter: Optional[List[Union[Label, str]]] = None,
+    ) -> Tuple[KnowledgeboxFindResults, str, Optional[Relations], Optional[str]]:
+        response = self.client.chat(self.build_chat_request(text, filter))
+        header = response.raw.read(4, decode_content=True)
+        payload_size = int.from_bytes(header, byteorder="big", signed=False)
+        data = response.raw.read(payload_size)
+        find_result = KnowledgeboxFindResults.parse_raw(base64.b64decode(data))
+        data = response.raw.read(decode_content=True)
+        answer, relations_payload = data.split(b"_END_")
+
+        learning_id = response.headers.get("NUCLIA-LEARNING-ID")
+        relations_result = None
+        if len(relations_payload) > 0:
+            relations_result = Relations.parse_raw(base64.b64decode(relations_payload))
+
+        return find_result, answer, relations_result, learning_id
+
+    def build_chat_request(
+        self,
+        text: str,
+        filter: Optional[List[Union[Label, str]]] = None,
+        min_score: Optional[float] = 0.70,
+        show: List[ResourceProperties] = [ResourceProperties.BASIC],
+        field_type_filter: List[FieldTypeName] = list(FieldTypeName),
+        extracted: List[ExtractedDataTypeName] = list(ExtractedDataTypeName),
+        context: Optional[List[Message]] = None,
+        fields: List[str] = [],
+        range_creation_start: Optional[datetime] = None,
+        range_creation_end: Optional[datetime] = None,
+        range_modification_start: Optional[datetime] = None,
+        range_modification_end: Optional[datetime] = None,
+    ) -> ChatRequest:
+        args: Dict[str, Any] = {
+            "features": [ChatOptions.PARAGRAPHS, ChatOptions.RELATIONS]
+        }
+        args["query"] = text
+
+        if filter is not None:
+            new_filter: List[Label] = []
+            for fil in filter:
+                if isinstance(fil, str):
+                    if len(fil.split("/")) == 1:
+                        lset = DEFAULT_LABELSET
+                        lab = fil
+                    else:
+                        lset, lab = fil.split("/")
+                    new_filter.append(Label(label=lab, labelset=lset))
+                else:
+                    new_filter.append(fil)
+            filter_list = [f"/l/{label.labelset}/{label.label}" for label in new_filter]
+            args["filters"] = filter_list
+
+        args["min_score"] = min_score
+        args["fields"] = fields
+        args["context"] = context
+        args["extracted"] = extracted
+        args["field_type_filter"] = field_type_filter
+        args["show"] = show
+        args["range_creation_start"] = range_creation_start
+        args["range_creation_end"] = range_creation_end
+        args["range_modification_start"] = range_modification_start
+        args["range_modification_end"] = range_modification_end
+
+        request = ChatRequest(**args)
+        return request
+
+    def build_find_request(
+        self,
+        text: Optional[str] = None,
+        filter: Optional[List[Union[Label, str]]] = None,
+        vector: Optional[Union[ndarray, List[float]]] = None,
+        vectorset: Optional[str] = None,
+        min_score: Optional[float] = 0.0,
+    ) -> FindRequest:
+        args: Dict[str, Any] = {"features": []}
+        if filter is not None:
+            new_filter: List[Label] = []
+            for fil in filter:
+                if isinstance(fil, str):
+                    if len(fil.split("/")) == 1:
+                        lset = DEFAULT_LABELSET
+                        lab = fil
+                    else:
+                        lset, lab = fil.split("/")
+                    new_filter.append(Label(label=lab, labelset=lset))
+                else:
+                    new_filter.append(fil)
+            filter_list = [f"/l/{label.labelset}/{label.label}" for label in new_filter]
+            args["filters"] = filter_list
+
+        if text is not None:
+            args["query"] = text
+            args["features"].append(SearchOptions.DOCUMENT)
+            args["features"].append(SearchOptions.PARAGRAPH)
+
+        if vector is not None and vectorset is not None:
+            vector = convert_vector(vector)
+
+            args["vector"] = vector
+            args["vectorset"] = vectorset
+            args["features"].append(SearchOptions.VECTOR)
+
+        if len(args["features"]) == 0:
+            args["features"].append(SearchOptions.DOCUMENT)
+            args["features"].append(SearchOptions.PARAGRAPH)
+
+        args["min_score"] = min_score
+        request = FindRequest(**args)
+        return request
+
     def build_search_request(
         self,
         text: Optional[str] = None,
         filter: Optional[List[Union[Label, str]]] = None,
         vector: Optional[Union[ndarray, List[float]]] = None,
         vectorset: Optional[str] = None,
         min_score: Optional[float] = 0.0,
```

## nucliadb_sdk/resource.py

```diff
@@ -24,15 +24,15 @@
 
 from nucliadb_models.common import Classification, FieldID
 from nucliadb_models.common import File as NDBModelsFile
 from nucliadb_models.file import FileField
 from nucliadb_models.link import LinkField
 from nucliadb_models.metadata import Origin, TokenSplit, UserFieldMetadata, UserMetadata
 from nucliadb_models.resource import Resource
-from nucliadb_models.text import TextField
+from nucliadb_models.text import TextField, TextFormat
 from nucliadb_models.utils import FieldIdString, SlugString
 from nucliadb_models.vectors import UserVector, UserVectorWrapper, VectorSet, VectorSets
 from nucliadb_models.writer import (
     GENERIC_MIME_TYPE,
     CreateResourcePayload,
     UpdateResourcePayload,
 )
@@ -48,14 +48,15 @@
 
 logger = logging.getLogger("nucliadb_sdk")
 
 
 def create_resource(
     key: Optional[str] = None,
     text: Optional[str] = None,
+    format: Optional[TextFormat] = None,
     binary: Optional[Union[File, str]] = None,
     labels: Optional[Labels] = None,
     entities: Optional[Entities] = None,
     vectors: Optional[Union[Vectors, Dict[str, Union[ndarray, List[float]]]]] = None,
     vectorsets: Optional[VectorSets] = None,
     icon: Optional[str] = None,
 ) -> CreateResourcePayload:
@@ -66,15 +67,19 @@
         create_payload.slug.validate(key)
     if icon is not None:
         create_payload.icon = icon
     else:
         create_payload.icon = GENERIC_MIME_TYPE
     main_field = None
     if text is not None:
-        create_payload.texts[FieldIdString("text")] = TextField(body=text)
+        if format is None:
+            format = TextFormat.PLAIN
+        create_payload.texts[FieldIdString("text")] = TextField(
+            body=text, format=format
+        )
         main_field = FieldID(field_type=FieldID.FieldType.TEXT, field="text")
     if binary is not None:
         if isinstance(binary, str):
             with open(binary, "rb") as binary_file:
                 data = binary_file.read()
                 binary = File(data=data, filename=binary.split("/")[-1])
         assert isinstance(binary, File)
@@ -172,25 +177,30 @@
 
     return create_payload
 
 
 def update_resource(
     resource: Resource,
     text: Optional[str] = None,
+    format: Optional[TextFormat] = None,
     binary: Optional[Union[File, str]] = None,
     labels: Optional[Labels] = None,
     entities: Optional[Entities] = None,
     vectors: Optional[Union[Vectors, Dict[str, Union[ndarray, List[float]]]]] = None,
     vectorsets: Optional[VectorSets] = None,
 ) -> UpdateResourcePayload:
     upload_payload = UpdateResourcePayload()
 
     main_field = None
     if text is not None:
-        upload_payload.texts[FieldIdString("text")] = TextField(body=text)
+        if format is None:
+            format = TextFormat.PLAIN
+        upload_payload.texts[FieldIdString("text")] = TextField(
+            body=text, format=format
+        )
         main_field = FieldID(field_type=FieldID.FieldType.TEXT, field="text")
     if binary is not None:
         if isinstance(binary, str):
             with open(binary, "rb") as binary_file:
                 data = binary_file.read()
                 binary = File(data=data, filename=binary.split("/")[-1])
```

## nucliadb_sdk/tests/fixtures.py

```diff
@@ -13,35 +13,46 @@
 # but WITHOUT ANY WARRANTY; without even the implied warranty of
 # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
 # GNU Affero General Public License for more details.
 #
 # You should have received a copy of the GNU Affero General Public License
 # along with this program. If not, see <http://www.gnu.org/licenses/>.
 #
+import asyncio
 import os
+from dataclasses import dataclass
+from typing import Optional
 from uuid import uuid4
 
 import pytest
 import requests
 from pytest_docker_fixtures import images  # type: ignore
 from pytest_docker_fixtures.containers._base import BaseImage  # type: ignore
 
+from nucliadb_client.client import NucliaDBClient as GRPCNucliaDBClient
 from nucliadb_models.resource import KnowledgeBoxObj
 from nucliadb_sdk.client import Environment, NucliaDBClient
 from nucliadb_sdk.knowledgebox import KnowledgeBox
 
 images.settings["nucliadb"] = {
     "image": "nuclia/nucliadb",
     "version": "latest",
     "env": {
         "NUCLIADB_DISABLE_TELEMETRY": "True",
+        "dummy_processing": "True",
         "max_receive_message_length": "40",
+        "TEST_SENTENCE_ENCODER": "multilingual-2023-02-21",
+        "TEST_RELATIONS": """{"tokens": [{"text": "Nuclia", "ner": "ORG"}]}""",
     },
 }
 
+NUCLIA_DOCS_dataset = (
+    "https://storage.googleapis.com/config.flaps.dev/test_nucliadb/nuclia.export"
+)
+
 
 class NucliaDB(BaseImage):
     name = "nucliadb"
     port = 8080
 
     def check(self):
         try:
@@ -87,7 +98,54 @@
     )
     yield KnowledgeBox(client)
 
     response = requests.delete(
         f"{api_path}/kb/{kbid}", headers={"X-NUCLIADB-ROLES": f"MANAGER"}
     )
     assert response.status_code == 200
+
+
+@dataclass
+class SDKFixture:
+    host: str
+    port: int
+    grpc: int
+    container: Optional[NucliaDB] = None
+
+
+async def init_fixture(
+    nucliadb: SDKFixture,
+    dataset_slug: str,
+    dataset_location: str,
+):
+    client = GRPCNucliaDBClient(
+        host=nucliadb.host, grpc=nucliadb.grpc, http=nucliadb.port, train=0
+    )
+    client.init_async_grpc()
+    kbid = await client.import_kb(slug=dataset_slug, location=dataset_location)
+    await client.finish_async_grpc()
+    return kbid
+
+
+@pytest.fixture(scope="session")
+def nucliadb_imported():
+    ndb = NucliaDB()
+    host, port = ndb.run()
+    network = ndb.container_obj.attrs["NetworkSettings"]
+
+    if os.environ.get("TESTING", "") == "jenkins":
+        grpc = 8060
+    else:
+        service_port = "8060/tcp"
+        grpc = network["Ports"][service_port][0]["HostPort"]
+    yield SDKFixture(host=host, port=port, grpc=grpc, container=ndb.container_obj)
+    ndb.stop()
+
+
+@pytest.fixture(scope="session")
+def docs_fixture(nucliadb_imported: SDKFixture):
+    kbid = asyncio.run(init_fixture(nucliadb_imported, "docs", NUCLIA_DOCS_dataset))
+    client = NucliaDBClient(
+        environment=Environment.OSS,
+        url=f"http://{nucliadb_imported.host}:{nucliadb_imported.port}/api/v1/kb/{kbid}",
+    )
+    return KnowledgeBox(client)
```

## Comparing `nucliadb_sdk-2.7.0.post167.dist-info/METADATA` & `nucliadb_sdk-2.7.0.post168.dist-info/METADATA`

 * *Files 14% similar despite different names*

```diff
@@ -1,21 +1,21 @@
 Metadata-Version: 2.1
 Name: nucliadb-sdk
-Version: 2.7.0.post167
+Version: 2.7.0.post168
 Summary: UNKNOWN
 Home-page: https://nucliadb.com
 License: BSD
 Platform: UNKNOWN
 Classifier: Development Status :: 4 - Beta
 Classifier: Programming Language :: Python :: 3.9
 Classifier: Topic :: Software Development :: Libraries :: Python Modules
 Classifier: License :: OSI Approved :: GNU Affero General Public License v3 or later (AGPLv3+)
 Requires-Dist: httpx
 Requires-Dist: requests
-Requires-Dist: nucliadb-models (==2.7.0-post167)
+Requires-Dist: nucliadb-models (==2.7.0-post168)
 
 # NucliaDB SDK
 
 NucliaDB Cloud and NucliaDB OSS sdk
 
 Update and compile the nucliadb image locally before running the tests.
 From nucliadb root dir:
```

## Comparing `nucliadb_sdk-2.7.0.post167.dist-info/RECORD` & `nucliadb_sdk-2.7.0.post168.dist-info/RECORD`

 * *Files 14% similar despite different names*

```diff
@@ -1,24 +1,27 @@
 nucliadb_sdk/__init__.py,sha256=JwbqnEIcZH81SBm_WP_Fb5RdamFQRNWLpceZnlkTilQ,1440
-nucliadb_sdk/client.py,sha256=QCkqrPiwps8o-9E520A4StqVrEBYRwFbI9klfvs0TGM,16458
+nucliadb_sdk/client.py,sha256=Mh4rQmnnbg5e2enkSubEaGq5OIwow_9o4c6rBil00AA,18079
 nucliadb_sdk/entities.py,sha256=IMgRL2dj_kFw7z6TeKxGS5UZ5_ZfszDrKyiLt6o-m9M,1051
 nucliadb_sdk/file.py,sha256=OrgNqziXl15c981zMHlklpWiYENMsgeglFZyvlac71I,978
-nucliadb_sdk/knowledgebox.py,sha256=H41eG1xPRHaUeMAfEcQqJtE4853QqxzFAniiIrXQo90,13121
+nucliadb_sdk/find.py,sha256=MbfcVxBRgjdMMbS1ZYmJujbSIsQ_xomBwwGOr7vNsvk,1937
+nucliadb_sdk/knowledgebox.py,sha256=hUcXcFCHl24hR2NVVzngEX3hv-lieaGtZKDbXkUMQBg,19218
 nucliadb_sdk/labels.py,sha256=hJuyOnDSKWZ-Y1Py_PYebD579Nidp0NVsq8uiniz8ac,1302
 nucliadb_sdk/py.typed,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-nucliadb_sdk/resource.py,sha256=3SukeZAUWtQxY-mrNcX345NAFExaNcm9RTOzOFzSjvk,14188
+nucliadb_sdk/resource.py,sha256=0jdBpClt3mo2hBaT_p-oqArDefnil26yYAd4BDnmPBs,14486
 nucliadb_sdk/search.py,sha256=qTxq7Ct9TDL5eBSGDt-gUPoDh0pByyv3jVRbWWt-raM,3763
 nucliadb_sdk/utils.py,sha256=GGMilqdjWX6pm1JX211-pI5N7UeYSkbi-qX4IHC4R1M,4300
 nucliadb_sdk/vectors.py,sha256=gf-8adQuJONgywNZnRVDa_PrPoO71xs17mEdM6Qn3GI,1611
 nucliadb_sdk/tests/__init__.py,sha256=itSI7dtTwFP55YMX4iK7JzdMHS5CQVUiB1XzQu4UBh8,833
 nucliadb_sdk/tests/conftest.py,sha256=L7a9YyCqVDYDGQvNtC7HyK2F24yvoN0mAcDQfSi8EmQ,891
-nucliadb_sdk/tests/fixtures.py,sha256=hyfjgInAqGrXZxvxeNFhDMRzZmS07m3_NPqLQXbcTpI,2778
+nucliadb_sdk/tests/fixtures.py,sha256=2g4OX89sXoVq_Ur70z0jXIwtNJi7jHOkRyZ3WroTF5w,4511
+nucliadb_sdk/tests/test_chat_resources.py,sha256=jbW29qB0-2-i_1NsV3hB-SlwJSLrB3w6lSEpLdM0PwM,1277
 nucliadb_sdk/tests/test_create.py,sha256=eI2SUacgok1Yls593J1hsIK5j-NwdHjQbSTnNUv6xSw,1183
 nucliadb_sdk/tests/test_dict_resource.py,sha256=d9UIb39_uUGp5GojNgamzj4cCNIL7Ny5rgO_QVrOq7A,1715
+nucliadb_sdk/tests/test_find_resources.py,sha256=yAGHq3JfTwruVuzM9IhlyfUGLm8iumHwMjUk7BnheW4,1302
 nucliadb_sdk/tests/test_search_resource.py,sha256=APrK2u0ko9BWQJu-E6Yg85C0JL0ARfof__H02DZz9Q8,14102
 nucliadb_sdk/tests/test_set_resource.py,sha256=cwLcDgkp3M1jad31f4dwUYNwZUoUFYt-kPRHWUebnIM,3909
 nucliadb_sdk/tests/test_vectors.py,sha256=43hlY-Mj6kVwHexixs1YQ5ic5wQUax4Rz-oqEHkFQHE,1429
-nucliadb_sdk-2.7.0.post167.dist-info/METADATA,sha256=Pw47gtSMtwNl6xp90uIgDjdSO6_IKz1dNRp4JENv9RY,691
-nucliadb_sdk-2.7.0.post167.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
-nucliadb_sdk-2.7.0.post167.dist-info/top_level.txt,sha256=_dCwt_JnsZ3463lfvc5KcM2wUQJ9aSvKSsAAjGH8R0Y,13
-nucliadb_sdk-2.7.0.post167.dist-info/zip-safe,sha256=AbpHGcgLb-kRsJGnwFEktk7uzpZOCcBY74-YBdrKVGs,1
-nucliadb_sdk-2.7.0.post167.dist-info/RECORD,,
+nucliadb_sdk-2.7.0.post168.dist-info/METADATA,sha256=kdv_1XB8z8nqO7bssQ90Pf8o7seigXTy60ECvzTORjk,691
+nucliadb_sdk-2.7.0.post168.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
+nucliadb_sdk-2.7.0.post168.dist-info/top_level.txt,sha256=_dCwt_JnsZ3463lfvc5KcM2wUQJ9aSvKSsAAjGH8R0Y,13
+nucliadb_sdk-2.7.0.post168.dist-info/zip-safe,sha256=AbpHGcgLb-kRsJGnwFEktk7uzpZOCcBY74-YBdrKVGs,1
+nucliadb_sdk-2.7.0.post168.dist-info/RECORD,,
```

